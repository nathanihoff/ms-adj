---
output:
  # bookdown::word_document2:
    # reference_docx: "word-template.docx"
  bookdown::pdf_document2:
    toc: yes
    keep_tex: true
    number_sections: yes
    pandoc_args: !expr rmdfiltr::add_wordcount_filter(rmdfiltr::add_citeproc_filter(args = NULL))
    #latex_engine: xelatex
always_allow_html: true
header-includes:
  - \usepackage{caption}
  #- \usepackage{setspace}\doublespace
  # - \usepackage[nolists, fighead, tabhead]{endfloat}
  # - \usepackage{endnotes}
  # - \let\footnote=\endnote
  # - \setlength{\headheight}{14.5pt}
  # - \setlength{\headheight}{13.6pt}
  # - \usepackage{fancyhdr}
  # - \pagestyle{fancy}
  # - \lhead{N.I. Hoffmann} 
  # - \rhead{`r format(Sys.time(), '%B %e, %Y')`}
  # - \counterwithin{figure}{section}
  # - \counterwithin{table}{section}


editor_options: 
  chunk_output_type: console


citeproc: no
#fontfamily: mathpazo
# fontsize: 12pt
# geometry: margin=.6in
indent: yes
link-citations: yes
linkcolor: blue
lang: 'en-US'

bibliography: "/Users/nathan/Documents/My Library.bib" 
# bibliography: "My Library.bib"  
csl: apa.csl
# csl: american-sociological-association.csl

title: "Supplementary Material"
subtitle: "Double Robust, Flexible Adjustment Methods for Causal Inference: An Overview and an Evaluation"

# author:  Nathan I. Hoffmann, Departments of Sociology and Statistics, UCLA
# date: "`r format(Sys.time(), '%B %e, %Y')`"


---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F, cache = T, dev = c('pdf', 'png'), fig.retina = 3, ft.latex.float = 'float')
options("yaml.eval.expr" = TRUE)

library(SuperLearner)
library(broom)
library(knitr)
library(kableExtra)
library(here)
library(patchwork)
library(haven)
library(tidyverse)

knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark=",")
})


options("yaml.eval.expr" = TRUE, scipen = 3, digits = 2)

uclablue = '#2774AE'
gray = '#808080'
black = '#000000'
ucla_palette = c(black, uclablue, gray)

# theme_set(theme_cowplot(font_family = 'Palatino') + 
theme_set(theme_classic(base_family = 'Palatino') + 
      theme(legend.title=element_blank(), 
         panel.grid.major.y = element_line('grey80'),
         legend.background = element_rect(fill = alpha("white", 0.5))
         ))
ggplot <- function(...) ggplot2::ggplot(...) + 
  scale_color_brewer(palette="Dark2") +
  scale_fill_brewer(palette="Dark2")

kable <- function(...) knitr::kable(..., format.args = list(big.mark = ","))
```




```{r load}


unemp_func <- function(x){
  x %>%
    as.data.frame() %>%
    mutate(re74_0 = re74 == 0,
         re75_0 = re75 == 0) 
}

lalonde_exp <- read_dta(here('data', 'nsw.dta')) %>%
  as.data.frame() %>%
  mutate(re75_0 = re75 == 0)
lalonde_exp_74 <- read_dta(here('data', 'nsw_dw.dta')) %>%
  unemp_func()
lalonde_cps1_controls <- read_dta(here('data', 'cps_controls.dta')) %>%
  unemp_func()
lalonde_cps3_controls <- read_dta(here('data', 'cps_controls3.dta')) %>%
  unemp_func()
lalonde_psid1_controls <- read_dta(here('data', 'psid_controls.dta')) %>%
  unemp_func()
lalonde_psid3_controls <- read_dta(here('data', 'psid_controls3.dta')) %>%
  unemp_func()
```

```{r functions}
## Pred functions ####
ols_logit_pred <- function(y, d, x){
  if('factor' %in% unlist(lapply(x, class))){
    x <- fastDummies::dummy_cols(x, remove_first_dummy = T, remove_selected_columns = T) 
  }
  
  mu_mod <- lm(y ~  d + ., data.frame(y, d, x))
  mu1_pred <- predict(mu_mod, newdata = data.frame(y, d = 1, x))
  mu0_pred <- predict(mu_mod, newdata = data.frame(y, d = 0, x))
  
  pi_mod <- glm(d ~ ., data.frame(y, x), family = binomial(link = 'logit'))
  pi_pred <- predict(pi_mod, type = 'response')
  
  # pi_pred <-case_when(
  #   pi_pred < .01 ~ .01,
  #   pi_pred > .99 ~ .99,
  #   T ~ pi_pred)

  
  return(
    list(
      mu1_pred = mu1_pred, 
      mu0_pred = mu0_pred, 
      pi_pred = pi_pred,
      d = d,
      y = y
    ))
}


grf_pred <- function(y, d, x){
  if('factor' %in% unlist(lapply(x, class))){
    x <- fastDummies::dummy_cols(x, remove_first_dummy = T, remove_selected_columns = T) 
  }
  
  forest_mu <- grf::regression_forest(X = data.frame(d, x), Y = y, 
                                 tune.parameters = "all")
  mu0_pred <- predict(forest_mu, newdata = data.frame(d = 0, x))$predictions
  mu1_pred <- predict(forest_mu, newdata = data.frame(d = 1, x))$predictions
  
  forest_pi <- grf::regression_forest(X = x, Y = d, tune.parameters = "all")
  pi_pred <- predict(forest_pi, newdata = x)$predictions

  return(
    list(
      mu1_pred = mu1_pred, 
      mu0_pred = mu0_pred, 
      pi_pred = pi_pred,
      d = d,
      y = y
    ))
}

superlearner_pred <- function(y, d, x, folds = 5, seed = 158){
  if('factor' %in% unlist(lapply(x, class))){
    x <- fastDummies::dummy_cols(x, remove_first_dummy = T, remove_selected_columns = T) 
  }
  
  set.seed(seed)
  mu_fit <- SuperLearner(
    Y = y,
    X = data.frame(d, x),
    cvControl = list(V = folds),
    SL.library=c("SL.glm", 
                 "SL.glmnet", 
                 "SL.xgboost"),
    method="method.CC_nloglik", 
    family= gaussian()
  )
  
  pi_fit <- SuperLearner(
    Y = d,
    X = x,
    cvControl = list(V = folds),
    SL.library=c("SL.glm", 
                 "SL.glmnet", 
                 "SL.xgboost"),
    method="method.CC_nloglik", 
    family= binomial()
  )
  

  return(list(
    mu0_pred = as.numeric(predict(mu_fit, newdata = data.frame(d = 0, x), type = 'response')$library.predict %*% mu_fit$coef),
    mu1_pred = as.numeric(predict(mu_fit, newdata = data.frame(d = 1, x), type = 'response')$library.predict %*% mu_fit$coef),
    pi_pred = as.numeric(predict(pi_fit, type = 'response')$pred),
    d = d,
    y = y))
}

## Methods ####

lm_sim <- function(dat){
  
  n <- length(dat)
  lm_list <- list()
  for(i in 1:n){
    start_time <- Sys.time()
    
    print(paste0(i, ' out of ', n))
    sim_dat <- data.frame(y = dat[[i]]$y, 
                          d = ifelse(dat[[i]]$z == 'trt', 1, 0), 
                          dat[[i]]$x)
    
    ate <- NA
    tryCatch({
      lm_out <- tidy(lm(y ~ d + ., sim_dat))
      ate <- lm_out[[2,2]]
      
      }, error=function(e){
        cat("ERROR :",conditionMessage(e), "\n")
        })
    
    lm_list[[i]] <- data.frame(dataset = i,
                               ate = ate,
                               #se = lm_out[[2,3]],
                               truth = mean(dat[[i]]$y.1) - mean(dat[[i]]$y.0),
                               dorie_dataset = dat[[i]]$dataset,
                               set = dat[[i]]$set,
                               size = dat[[i]]$size,
                               comp_time = as.numeric(difftime(Sys.time(), start_time, units = 'secs')))
    
  }
  
  # fail_count <- sum(sapply(lm_list, function(x) is.null(x)))
  # # in case last few are errors
  # fail_count <- ifelse(length(lm_list) == n, fail_count, fail_count + (n - length(lm_list)))
  
  # end_time <- Sys.time()
  
  return(bind_rows(lm_list))
  
  # return(list(
  #   est_df = bind_rows(lm_list)
  #   fail_count = fail_count,
  #   comp_time = as.numeric(difftime(end_time, start_time, units = 'secs'))/(n-fail_count))
  #   ))
}


psm_sim <- function(dat){
  
  n <- length(dat)
  psm_list <- list()
  for(i in 1:n){
    print(paste0(i, ' out of ', n))
    
    start_time <- Sys.time()
    
    sim_dat <- data.frame(y = dat[[i]]$y, 
                          d = ifelse(dat[[i]]$z == 'trt', 1, 0), 
                          dat[[i]]$x)
    
    ate <- NA
    
    tryCatch({
      form <- as.formula(paste0('d ~ ', paste(names(dat[[i]]$x), collapse = '+')))
      match_out <- MatchIt::matchit(form,
                             data = sim_dat,
                             method = 'nearest',
                             distance = 'glm') 
      
      # match_data <- MatchIt::match.data(match_out) 
      # apply(match_data, 1, unique)
      form2 <- as.formula(paste0('y ~ d + ', paste(names(dat[[i]]$x), collapse = '+')))
      
    
      psm_out <- lm(form2, 
                    MatchIt::match.data(match_out), 
                    weights = weights) %>%
        tidy()
      
      ate <- psm_out[[2,2]]
        
  }, error=function(e){
    cat("ERROR :",conditionMessage(e), "\n")
    })
    
    psm_list[[i]] <- data.frame(dataset = i,
                                ate = ate,
                                # se = psm_out[[2,3]],
                                truth = mean(dat[[i]]$y.1) - mean(dat[[i]]$y.0),
                                dorie_dataset = dat[[i]]$dataset,
                                set = dat[[i]]$set,
                                size = dat[[i]]$size,
                                comp_time = as.numeric(difftime(Sys.time(), start_time, units = 'secs')))
  }
  
  # fail_count <- sum(sapply(psm_list, function(x) is.null(x)))
  # # in case last few are errors
  # fail_count <- ifelse(length(psm_list) == n, fail_count, fail_count + (n - length(psm_list)))
  
  # end_time <- Sys.time()
  
  return(bind_rows(psm_list))
  
  # return(list(
  #   est_df = bind_rows(psm_list),
  #   fail_count = fail_count,
  #   comp_time = as.numeric(difftime(end_time, start_time, units = 'secs'))/(n-fail_count))
  # )
}


aipw_calc <- function(mu1_pred, mu0_pred, pi_pred, d, y){
  n <- length(mu1_pred)
  
  y1_pred <- (d*(y-mu1_pred))/pi_pred + mu1_pred
  y0_pred <- ((1-d)*(y-mu0_pred))/(1-pi_pred) + mu0_pred
  
  ate <- (1/n)*(sum(y1_pred)) - (1/n)*sum(y0_pred)
  
  return(ate)
}

aipw_calc_trunc <- function(mu1_pred, mu0_pred, pi_pred, d, y){
  n <- length(mu1_pred)
  
  # pi_pred <- case_when(
  #   pi_pred < quantile(pi_pred, .025) ~ quantile(pi_pred, .025),
  #   pi_pred > quantile(pi_pred, .975) ~ quantile(pi_pred, .975),
  #   T ~ pi_pred)
  
  pi_pred <- case_when(
    pi_pred < .01 ~ .01,
    pi_pred > .99 ~ .99,
    T ~ pi_pred)
  
  y1_pred <- (d*(y-mu1_pred))/pi_pred + mu1_pred
  y0_pred <- ((1-d)*(y-mu0_pred))/(1-pi_pred) + mu0_pred
  
  ate <- (1/n)*(sum(y1_pred)) - (1/n)*sum(y0_pred)
  
  return(ate)
}


tmle_calc <- function(mu1_pred, mu0_pred, pi_pred, d, y){
  n <- length(y)
  # H <- (d == 1)/pi_pred - (d==0)/(1-pi_pred)
  H0 = (1-d)/(1-pi_pred)
  H1 = d/pi_pred

  epsilon <- glm(y ~ -1 + H0 + H1 + offset(qlogis((d==1)*mu1_pred 
                    + (d==0)*mu0_pred)),
                 family = binomial(link = 'logit')) %>%
    tidy() %>%
    pull(estimate)
  
  H_0 = (1-d)/(1-pi_pred)
  H_1 = d/pi_pred
  
  target_0 <- plogis(qlogis(mu0_pred + epsilon[1]*H_0))
  target_1 <- plogis(qlogis(mu1_pred + epsilon[2]*H_1))
  
  ATE <- mean((target_1 - target_0), na.rm = T)
  return(ATE)
}

dml_pre <- function(y, d, x){
  if('factor' %in% unlist(lapply(x, class))){
    x <- fastDummies::dummy_cols(x, remove_first_dummy = T, remove_selected_columns = T) 
  }
  
  n <- length(y)
  n_2 <- n/2
  n_2_1 = ifelse(round(n_2) == n_2, n_2, round(n_2))
  n_2_2 = ifelse(round(n_2) == n_2, n_2, round(n_2)+1)
  
  # split the sample
  random_vec <- sample(1:n, n)
  I <- random_vec[1:n_2_1]
  I_c <- random_vec[(n_2_1+1):n]
  
  return(list(
    y_I = y[I],
    d_I = d[I],
    x_I = x[I,], 
    y_I_c = y[I_c],
    d_I_c = d[I_c],
    x_I_c = x[I_c,]
    ))
}

dml_post <- function(y_I, d_I, x_I = NULL, y_I_c, d_I_c, x_I_c = NULL,
                     mu_pred1, pi_pred1, mu_pred2, pi_pred2){
  
  v1 <- d_I - pi_pred1
  delta1 <- (sum(v1 * d_I))^-1 * sum(v1 * (y_I - pi_pred1))
  
  v2 <- d_I_c - pi_pred2
  delta2 <- (sum(v2 * d_I_c))^-1 * sum(v2 * (y_I_c - pi_pred2))
  
  ate <- (delta1 + delta2)/2
  
  return(ate)
}

## Predictor functions
ols_logit_dml <- function(y_I, d_I, x_I, y_I_c, d_I_c, x_I_c){
  mu_mod1 <- lm(y ~ ., data.frame(y = y_I_c, x_I_c))
  mu_pred1 <- predict(mu_mod1, newdata = data.frame(y = y_I, x_I))

  pi_mod1 <- glm(d ~ ., data.frame(d = d_I_c, x_I_c), 
                family = binomial(link = 'logit'))
  pi_pred1 <- predict(pi_mod1, 
                     newdata = data.frame(d = d_I, x_I), 
                     type = 'response')
  
  mu_mod2 <- lm(y ~ ., data.frame(y = y_I, x_I))
  mu_pred2 <- predict(mu_mod2, newdata = data.frame(y = y_I_c, x_I_c))

  pi_mod2 <- glm(d ~ ., data.frame(d = d_I, x_I), 
                family = binomial(link = 'logit'))
  pi_pred2 <- predict(pi_mod2, 
                     newdata = data.frame(d = d_I_c, x_I_c), 
                     type = 'response')
  
  return(list(
    mu_pred1 = mu_pred1,
    pi_pred1 = pi_pred1,
    mu_pred2 = mu_pred2,
    pi_pred2 = pi_pred2
  ))
}

grf_dml <- function(y_I, d_I, x_I, y_I_c, d_I_c, x_I_c){
  mu_mod1 <- grf::regression_forest(X = x_I_c, Y = y_I_c, 
                                       tune.parameters = "all")
  mu_pred1 <- predict(mu_mod1, newdata = x_I)$predictions
  
  pi_mod1 <- grf::regression_forest(X = x_I_c, Y = d_I_c, tune.parameters = "all")
  pi_pred1 <- predict(pi_mod1, newdata = x_I)$predictions
  
  mu_mod2 <- grf::regression_forest(X = x_I, Y = y_I, 
                                       tune.parameters = "all")
  mu_pred2 <- predict(mu_mod2, newdata = x_I_c)$predictions
  
  pi_mod2 <- grf::regression_forest(X = x_I, Y = d_I, tune.parameters = "all")
  pi_pred2 <- predict(pi_mod2, newdata = x_I_c)$predictions

  
  return(list(
    mu_pred1 = mu_pred1,
    pi_pred1 = pi_pred1,
    mu_pred2 = mu_pred2,
    pi_pred2 = pi_pred2
  ))
}

superlearner_dml <- function(y_I, d_I, x_I, y_I_c, d_I_c, x_I_c,
                             folds = 5){
  
  
  mu_mod1 <- SuperLearner(
    Y = y_I_c,
    X = x_I_c,
    cvControl = list(V = folds),
    SL.library=c("SL.glm", 
                 "SL.glmnet", 
                 "SL.xgboost"),
    method="method.CC_nloglik", 
    family=gaussian()
  )
  
  pi_mod1 <- SuperLearner(
    Y = d_I_c,
    X = x_I_c,
    cvControl = list(V = folds),
    SL.library=c("SL.glm", 
                 "SL.glmnet", 
                 "SL.xgboost"),
    method="method.CC_nloglik", 
    family=binomial()
  )
  
  
  mu_pred1 <- predict(mu_mod1, newdata = x_I, type = 'response')$library.predict %*% mu_mod1$coef
  pi_pred1 <- predict(pi_mod1, newdata = x_I, type = 'response')$pred
  
  mu_mod2 <- SuperLearner(
    Y = y_I,
    X = x_I,
    cvControl = list(V = folds),
    SL.library=c("SL.glm", 
                 "SL.glmnet", 
                 "SL.xgboost"),
    method="method.CC_nloglik", 
    family=gaussian()
  )
  
  pi_mod2 <- SuperLearner(
    Y = d_I,
    X = x_I,
    cvControl = list(V = folds),
    SL.library=c("SL.glm", 
                 "SL.glmnet", 
                 "SL.xgboost"),
    method="method.CC_nloglik", 
    family=binomial()
  )
  
  mu_pred2 <- predict(mu_mod2, newdata = x_I_c, type = 'response')$library.predict %*% mu_mod2$coef
  pi_pred2 <- predict(pi_mod2, newdata = x_I_c, type = 'response')$pred
  
  return(list(
    mu_pred1 = mu_pred1,
    pi_pred1 = pi_pred1,
    mu_pred2 = mu_pred2,
    pi_pred2 = pi_pred2
  ))
}


lm_lin_continuous <- function (formula, covariates, data, weights, subset, clusters, 
  se_type = NULL, ci = TRUE, alpha = 0.05, return_vcov = TRUE, 
  try_cholesky = FALSE) 
{
  if (length(all.vars(f_rhs(formula))) > 1) {
    stop("The `formula` argument, `", format(formula), "`, must only have the ", 
      "treatment variable on the right-hand side of the formula. Covariates ", 
      "should be specified in the `covariates` argument like so:\n`covariates = ", 
      paste0("~ ", paste(all.vars(f_rhs(formula))[-1], 
        sep = " + ")), "`.", "\n\n See ?lm_lin.")
  }
  if (!inherits(covariates, "formula")) {
    stop("The `covariates` argument must be specified as a formula:\n", 
      "You passed an object of class ", class(covariates))
  }
  cov_terms <- terms(covariates)
  if (attr(cov_terms, "response") != 0) {
    stop("Must not specify a response variable in `covariates`` formula.\n", 
      "`covariates` must be a right-sided formula, such as '~ x1 + x2 + x3'")
  }
  if (length(attr(cov_terms, "order")) == 0) {
    stop("`covariates` must have a variable on the right-hand side, not 0 or 1")
  }
  full_formula <- update(formula, reformulate(c(".", labels(cov_terms))))
  datargs <- enquos(formula = full_formula, weights = weights, 
    subset = subset, cluster = clusters)
  data <- enquo(data)
  model_data <- clean_model_data(data = data, datargs)
  outcome <- as.matrix(model_data$outcome)
  n <- nrow(outcome)
  design_matrix <- model_data$design_matrix
  weights <- model_data$weights
  cluster <- model_data$cluster
  has_intercept <- attr(terms(formula), "intercept")
  treat_col <- which(attr(design_matrix, "assign") == 1)
  treatment <- design_matrix[, treat_col, drop = FALSE]
  design_mat_treatment <- colnames(design_matrix)[treat_col]
  # if (any(!(treatment %in% c(0, 1)))) {
  #   vals <- sort(unique(treatment))
  #   if (has_intercept) 
  #     vals <- vals[-1]
  #   n_treats <- length(vals)
  #   names(vals) <- paste0(colnames(design_matrix)[treat_col], 
  #     vals)
  #   treatment <- outer(drop(treatment), vals, function(x, 
  #     y) as.numeric(x == y))
  # }
  demeaned_covars <- design_matrix[, setdiff(colnames(design_matrix), 
    c(design_mat_treatment, "(Intercept)")), drop = FALSE]
  if (is.numeric(weights)) {
    center <- apply(demeaned_covars, 2, weighted.mean, weights)
  }
  else {
    center <- colMeans(demeaned_covars)
  }
  demeaned_covars <- sweep(demeaned_covars, 2, center)
  original_covar_names <- colnames(demeaned_covars)
  colnames(demeaned_covars) <- paste0(ifelse(grepl("\\:|(^.+\\()", 
    colnames(demeaned_covars)), paste0("(", colnames(demeaned_covars), 
    ")"), colnames(demeaned_covars)), "_c")
  n_treat_cols <- ncol(treatment)
  n_covars <- ncol(demeaned_covars)
  n_int_covar_cols <- n_covars * (n_treat_cols)
  interacted_covars <- matrix(0, nrow = n, ncol = n_int_covar_cols)
  interacted_covars_names <- character(n_int_covar_cols)
  for (i in 1:n_covars) {
    covar_name <- colnames(demeaned_covars)[i]
    cols <- (i - 1) * n_treat_cols + (1:n_treat_cols)
    interacted_covars[, cols] <- treatment * demeaned_covars[, 
      i]
    interacted_covars_names[cols] <- paste0(colnames(treatment), 
      ":", covar_name)
  }
  colnames(interacted_covars) <- interacted_covars_names
  if (has_intercept) {
    X <- cbind(matrix(1, nrow = n, ncol = 1, dimnames = list(NULL, 
      "(Intercept)")), treatment, demeaned_covars, interacted_covars)
  }
  else {
    if (n_treat_cols == 1) {
      X <- cbind(treatment, demeaned_covars, interacted_covars)
    }
    else {
      X <- cbind(treatment, interacted_covars)
    }
  }
  return_list <- lm_robust_fit(y = outcome, X = X, weights = weights, 
    cluster = cluster, ci = ci, se_type = se_type, alpha = alpha, 
    return_vcov = return_vcov, try_cholesky = try_cholesky, 
    has_int = has_intercept, iv_stage = list(0))
  return_list <- lm_return(return_list, model_data = model_data, 
    formula = formula)
  return_list[["scaled_center"]] <- center
  setNames(return_list[["scaled_center"]], original_covar_names)
  return_list[["call"]] <- match.call()
  return(return_list)
}

environment(lm_lin_continuous) <- asNamespace('estimatr')
assignInNamespace("lm_lin", lm_lin_continuous, ns = "estimatr")



## Functions using double robust packages ####
aipw_sim <- function(dat, seed = 185){

  start_time <- Sys.time()
  
  set.seed(seed)
  n <- length(dat)
  aipw_list <- list()
  # fail_count <- 0
  
  for(i in 1:n){
    print(paste0(i, ' out of ', n))
    sim_dat <- data.frame(y = dat[[i]]$y, 
                          d = as.numeric(ifelse(dat[[i]]$z == 'trt', 1, 0)), 
                          dat[[i]]$x)
    
    tryCatch({
      sim_dat <- sim_dat %>%
        fastDummies::dummy_cols(remove_first_dummy = T, remove_selected_columns = T) 
      }, error=function(e){
      })

    tryCatch({
      forest <- grf::causal_forest(X = select(sim_dat, 3:length(names(sim_dat))), 
                                   Y = sim_dat$y, 
                                   W = sim_dat$d)
      # forest <- grf::causal_forest(X = select(sim_dat, starts_with('x')), 
      #                              Y = sim_dat$y, W = sim_dat$d)
      
      aipw_out <- grf::average_treatment_effect(forest, target.sample = 'treated', method = 'AIPW')
      
      aipw_list[[i]] <- data.frame(d = aipw_out[[1]],
                                   se = aipw_out[[2]],
                               truth = mean(dat[[i]]$y.1) - mean(dat[[i]]$y.0))
        
  }, error=function(e){
    cat("ERROR :",conditionMessage(e), "\n")
    })
  }
  
  fail_count <- sum(sapply(aipw_list, function(x) is.null(x)))
  # in case last few are errors
  fail_count <- ifelse(length(aipw_list) == n, fail_count, fail_count + (n - length(aipw_list)))
  
  
  end_time <- Sys.time()
  
  return(list(
      est_df = bind_rows(aipw_list),
      fail_count = fail_count,
      comp_time = as.numeric(difftime(end_time, start_time, units = 'secs'))/(n-fail_count))
  )
}

tmle_sim <- function(dat, seed = 185){
  start_time <- Sys.time()
  
  set.seed(seed)
  n <- length(dat)
  tmle_list <- list()
  # fail_count <- 0
  
  for(i in 1:n){
    print(paste0(i, ' out of ', n))
    sim_dat <- data.frame(y = dat[[i]]$y, 
                          d = ifelse(dat[[i]]$z == 'trt', 1, 0), 
                          dat[[i]]$x) 
    
    tryCatch({
      sim_dat <- sim_dat %>%
        fastDummies::dummy_cols(remove_first_dummy = T, remove_selected_columns = T) 
      }, error=function(e){
      })

    tryCatch({
      forest <- grf::causal_forest(X = select(sim_dat, 3:length(names(sim_dat))), 
                                   Y = sim_dat$y, W = sim_dat$d)
      # forest <- grf::causal_forest(X = select(sim_dat, starts_with('x')), 
      #   Y = sim_dat$y, W = sim_dat$d)
      
      tmle_out <- grf::average_treatment_effect(forest, target.sample = 'treated', method = 'TMLE')
      
      tmle_list[[i]] <- data.frame(d = tmle_out[[1]],
                                   se = tmle_out[[2]],
                               truth = mean(dat[[i]]$y.1) - mean(dat[[i]]$y.0))
        
  }, error=function(e){
    cat("ERROR :",conditionMessage(e), "\n")
    })
  }
  
  fail_count <- sum(sapply(tmle_list, function(x) is.null(x)))
  # in case last few are errors
  fail_count <- ifelse(length(tmle_list) == n, fail_count, fail_count + (n - length(tmle_list)))
  
  end_time <- Sys.time()
  
 return(list(
      est_df = bind_rows(tmle_list),
      fail_count = fail_count,
      comp_time = as.numeric(difftime(end_time, start_time, units = 'secs'))/(n-fail_count))
  )
}

dml_sim <- function(dat, seed = 185){
  
  start_time <- Sys.time()
  
  set.seed(seed)
  
  n <- length(dat)
  
  dml_list <- list()
  
  for(i in 1:n){
    print(paste0(i, ' out of ', n))
    sim_dat <- data.frame(y = dat[[i]]$y, 
                          d = ifelse(dat[[i]]$z == 'trt', 1, 0), 
                          dat[[i]]$x) 
    
    lgr::get_logger("mlr3")$set_threshold("warn")
    
    learner = lrn("regr.ranger", num.trees=500, 
                  max.depth=5, min.node.size=2)
    ml_l = learner$clone()
    ml_m = learner$clone()

    tryCatch({
      dml_out <- DoubleML::DoubleMLPLR$new(
        DoubleML::DoubleMLData$new(sim_dat,
                                 y_col = 'y',
                                 d_cols = 'd',
                                 x_cols = names(dat[[i]]$x)), 
        ml_l=ml_l, ml_m=ml_m)
      
      dml_out$fit()
      dml_list[[i]] <- data.frame(d = dml_out$all_coef[[1,1]],
                                  se = dml_out$all_se[[1,1]],
                               truth = mean(dat[[i]]$y.1) - mean(dat[[i]]$y.0))
      
  }, error=function(e){
    cat("ERROR :",conditionMessage(e), "\n")
    })
  }
  
  fail_count <- sum(sapply(dml_list, function(x) is.null(x)))
  # in case last few are errors
  fail_count <- ifelse(length(dml_list) == n, fail_count, fail_count + (n - length(dml_list)))
  
  end_time <- Sys.time()
  
  return(list(
      est_df = bind_rows(dml_list),
      fail_count = fail_count,
      comp_time = as.numeric(difftime(end_time, start_time, units = 'secs'))/(n-fail_count))
      )
}



## Other functions ####
normalize <- function(x, y){(x - min(y)) / (max(y) - min(y))}
denormalize <- function(x, y){x * (max(y) - min(y))}

perform <- function(est_df, label){
  est_df %>%
    # mutate(d = d/truth,
    #        truth = 1) %>%
    summarize(bias = mean(d - truth),
              percent_bias = bias/sd(d),
              rmse = sqrt(mean((ate - truth)^2)),
              mae = median(abs(d - truth))
              # fail_count = first(fail_count),
              # comp_time = first(comp_time)
              ) %>%
    mutate(label = label,
           n = nrow(est_df) + fail_count) %>%
    select(label, everything()) %>%
    return()
}

model_matrix <- function(...){
  options(na.action='na.pass')
  matrix_out <- model.matrix(...)
  options(na.action = 'na.omit')
  return(matrix_out)
}

p_val <- function(estimate, std.error){
  z <- estimate / std.error
  2*(1 - pnorm(abs(as.numeric(z))))
}

compare_tbl <- function(model_list, treatment, tidy = T){
  out_list <- list()
  k <- 1
  for(model_set in model_list){
    names(model_set$grf) <- c('estimate', 'std.error')
    
    if(tidy == T){
    original_model <- tidy(model_set$original) %>%
      filter(term == treatment)
    } else{
      original_model <- model_set$original
    }
    
    out_list[[k]] <- original_model %>%
      bind_rows(bind_rows(model_set$grf)) %>%
      bind_rows(model_set$dml) %>%
      bind_rows(model_set$dml_cre) %>%
      bind_rows(model_set$dml_wg_cre) %>%
      mutate(term = c('Original', 'AIPW (GRF)', 'DML (SuperLearner)', 
                      'DML (SuperLearner), CRE FE', 'DML (SuperLearner), hybrid FE'), 
             p.value = p_val(estimate, std.error)) %>%
      remove_rownames() %>%
      tibble()
    
    k <- k+1
  }
  return(out_list)
}

# compare_tbl_notidy <- function(model_list){
#   out_list <- list()
#   k <- 1
#   for(model_set in model_list){
#     names(model_set[[2]]) <- c('estimate', 'std.error')
#     
#     
#     out_list[[k]] <- model_set[[1]] %>%
#       bind_rows(bind_rows(model_set[[2]])) %>%
#       bind_rows(model_set[[3]]) %>%
#       mutate(term = c('Original', 'AIPW (GRF)', 'DML (SuperLearner)'), p.value = p_val(estimate, std.error)) %>%
#       tibble()
#     
#     k <- k+1
#   }
#   return(out_list)
# }

dml_grf <- function(outcome, treatment, covariates, clustervar = NULL, dataset, 
                    fe = T, target = 'treated', paper, model, drop_na_grf = F, seed = 123){
  set.seed(seed)
  
  dataset <- filter(dataset, !is.na(!!sym(outcome))) %>%
    select(all_of(c(treatment, outcome, covariates, clustervar)))
  
  if(drop_na_grf == T){
    dataset <- dataset %>%
      drop_na()
  }
  
  y <- as.numeric(dataset[[outcome]])
  X <- model_matrix(~., select(dataset, all_of(covariates)))[,]
  d <- as.numeric(dataset[[treatment]])
  
  grf_model <- grf::causal_forest(X = X, Y = y, W = d, seed = 123,
                        clusters = dataset[[clustervar]])
  
  grf_out <- grf::average_treatment_effect(grf_model, target.sample = target)
  
  
  dataset_drop_na <- as.data.frame(model_matrix(~., dataset)[,]) %>%
    # remove annoying characters
    rename_with(., ~ gsub("'", "", iconv(.x, from = "UTF-8", to='ASCII//TRANSLIT'))) %>%
    rename_with(., ~ gsub("\\[|\\]|\\/|\\*|\\)|\\(", "", .x)) %>%
    rename_with(., ~ gsub(" ", "", .x)) %>%
    # drop missing
    drop_na() %>%
    # remove uninformative columns
    select(where(~n_distinct(.) > 1)) 
  dataset_drop_na <- dataset_drop_na %>%
    left_join(dataset_drop_na %>%
                group_by(!!sym(clustervar)) %>%
                summarize(across(everything(), mean, .names = 'mean_{.col}')) %>%
                ungroup()) %>%
    mutate(intercept = 1)
  # covariates_design <- dataset_drop_na %>% 
  #   select(select(-c(treatment, outcome, clustervar))) %>%
  #   names() %>%
  #   append('intercept', after = 0)
  covariates_design <- names(dataset_drop_na)[!(names(dataset_drop_na) %in% c(treatment, outcome, clustervar)) &
                                                !str_detect(names(dataset_drop_na),  'mean_')]
  
  
  
  # dataset_drop_na$cov_mean <- dataset_drop_na %>%
  #   select(all_of(covariates_design)) %>%
  #   mutate_all(scale) %>%
  #   apply(1, mean)


  # dml_dataframe <- as.data.frame(cbind(y, d, 
  #                                      d_bar = dataset_drop_na[[paste0('mean_', treatment)]],
  #                                      as_tibble(X)[,-1], 
  #                                      as_tibble(mean_X)[,-1], 
  #                                      cluster = dataset_drop_na[[clustervar]]))
  
  
  graph_ensemble_regr = gunion(list(
      po("learner", lrn("regr.cv_glmnet", s = "lambda.min")),
      po("learner", lrn('regr.xgboost', max_depth = 4)),
      po("learner", lrn("regr.glm"))
    )) %>>%
      po("regravg", 3)
  
  ensemble_pipe_regr = as_learner(graph_ensemble_regr)
  
  # DML
  set.seed(seed)
  dml_data <- double_ml_data_from_data_frame(dataset_drop_na,
                                             x_cols = covariates_design,
                                             y_col = outcome,
                                             d_cols = treatment,
                                             cluster_cols = clustervar)
  
  # y <- as.numeric(dataset_drop_na[[outcome]])
  # # X <- select(dataset_drop_na, covariates_design)
  # X <- model_matrix(~., select(dataset_drop_na, all_of(covariates)))[,]
  # # mean_X <- model_matrix(~., select(dataset_drop_na, all_of(paste0('mean_', covariates))))[,]
  # d <- as.numeric(dataset_drop_na[[treatment]])
  # 
  # dml_data <- double_ml_data_from_matrix(X = X, y = y, d = d, 
  #                                        cluster_vars = dataset_drop_na[[clustervar]])
  
  # dml_data <- double_ml_data_from_matrix(X = select(dataset_drop_na, all_of(covariates_design)),
  #                                            y = dataset_drop_na[,outcome],
  #                                            d = dataset_drop_na[,treatment],
  #                                            cluster_vars = dataset_drop_na[,clustervar])
  obj_dml_plr_sim_pipe_ensemble = DoubleMLPLR$new(dml_data,
                                                  ml_l = ensemble_pipe_regr,
                                                  ml_m = ensemble_pipe_regr)
  obj_dml_plr_sim_pipe_ensemble$fit() 
  dml_out <- data.frame(estimate = obj_dml_plr_sim_pipe_ensemble$coef,
                         std.error = obj_dml_plr_sim_pipe_ensemble$se)
  
  if(fe == T){
    # DML CRE
    set.seed(seed)  
    dml_data_cre <- XTDML::dml_cre_data_from_data_frame(dataset_drop_na,
                                                 x_cols = covariates_design,
                                                 y_col = outcome,
                                                 d_cols = treatment,
                                                 xbar_cols = paste0('mean_', covariates_design[-length(covariates_design)]),
                                                 dbar_cols = paste0('mean_', treatment),
                                                 cluster_cols = clustervar)  
    obj_dml_cre = XTDML::dml_cre_plr$new(dml_data_cre,
                                         ml_l = ensemble_pipe_regr,
                                         ml_m = ensemble_pipe_regr)
    
    obj_dml_cre$fit()
    dml_cre_out <- data.frame(estimate = obj_dml_cre$coef_theta,
                           std.error = obj_dml_cre$se_theta)
  
  # DML WG-CRE
  require(parameters)
  set.seed(seed)  
  dml_data_wg_cre <- XTDML::dml_hybrid_data_from_data_frame(dataset_drop_na,
                                               x_cols = covariates_design,
                                               y_col = outcome,
                                               d_cols = treatment,
                                               xbar_cols = paste0('mean_', covariates_design[-length(covariates_design)]),
                                               dbar_cols = paste0('mean_', treatment),
                                               cluster_cols = clustervar)  
  obj_dml_wg_cre = XTDML::dml_hybrid_plr$new(dml_data_wg_cre,
                                       ml_l = ensemble_pipe_regr,
                                       ml_m = ensemble_pipe_regr)
  
  obj_dml_wg_cre$fit()
  dml_wg_cre_out <- data.frame(estimate = obj_dml_wg_cre$coef_theta,
                         std.error = obj_dml_wg_cre$se_theta)
  } else {
    dml_cre_out <- data.frame(estimate = NA,
                           std.error = NA)
    dml_wg_cre_out <- data.frame(estimate = NA,
                         std.error = NA)
  }
  
  return(list(grf = grf_out, 
              dml = dml_out,
              dml_cre = dml_cre_out,
              dml_wg_cre = dml_wg_cre_out))
}

```



```{r results-load}

lm_df <- read_csv(here('files', 'lm_df.csv')) %>%
  mutate(method = 'ols')

psm_df <- read_csv(here('files', 'psm_df.csv')) %>%
  mutate(method = 'psm')

lin_df <- read_csv(here('files', 'lin.csv')) %>%
  mutate(method = 'lin')

ipw_df <- read_csv(here('files', 'ipw.csv')) %>%
  mutate(estimator = method,
         method = 'ipw')

gcomp_df <- read_csv(here('files', 'gcomp.csv')) %>%
  mutate(estimator = method,
         method = 'g-comp')

aipw_df <- read_csv(here('files', 'aipw.csv')) %>%
  mutate(estimator = method,
         method = 'aipw')

aipw_trunc_df <- read_csv(here('files', 'aipw_trunc.csv')) %>%
  mutate(estimator = method,
         method = 'aipw')

tmle_df <- read_csv(here('files', 'tmle.csv')) %>%
  # filter(fail == F) %>%
  select(-fail) %>%
  mutate(estimator = method,
         method = 'tmle')

dml_df <- bind_rows(
  mutate(read_csv(here('files', 'dml_ols_logit.csv')), 
         estimator = 'ols_logit',
         method = 'dml',
         dataset = row_number()),
  mutate(read_csv(here('files', 'dml_grf.csv')), 
         estimator = 'grf',
         method = 'dml',
         dataset = row_number()),
  mutate(read_csv(here('files', 'dml_superlearner.csv')), 
         estimator = 'superlearner',
         method = 'dml',
         dataset = row_number())
) %>%
  select(names(tmle_df))

aipw_package_df <- read_csv(here('files', 'aipw_package.csv')) %>%
  mutate(estimator = 'grf (pack.)',
         method = 'aipw')

dml_package_df <- read_csv(here('files', 'dml_package.csv')) %>%
  mutate(estimator = 'superlearner (pack.)',
         method = 'dml')


sim_results <- bind_rows(lm_df, psm_df, lin_df, ipw_df, gcomp_df, aipw_trunc_df, tmle_df, dml_df, aipw_package_df, dml_package_df) %>%
  mutate(estimator = factor(estimator, levels = c('ols_logit', 'ols', 'logit', 
          'grf', 'grf (pack.)', 'superlearner', 'superlearner (pack.)')),
         method = factor(method, levels = c('ols', 'psm', 'ipw', 'g-comp', 'lin', 
                                            'aipw', 'tmle', 'dml'))) %>%
  arrange(method, estimator) %>%
  #mutate(estimator = ifelse(is.na(estimator), 'NA', estimator)) %>%
  mutate(bias = ate - truth,
         method_estimator = ifelse(is.na(estimator), as.character(method), paste0(method, ', ', estimator))) %>%
  mutate(method_estimator = factor(method_estimator, levels = unique({.$method_estimator}))) 

# write_csv(sim_results, here('files', 'lalonde_means.csv'))
```


\renewcommand{\thesection}{S\arabic{section}}
\renewcommand{\thepage}{S\arabic{page}}

<!-- # (APPENDIX) Appendix {-} -->

\newpage

<!-- # LaLonde NSW Data -->

```{r lalonde-packages, eval = F}
library(grf)
library(DoubleML)
library(mlr3)
library(mlr3pipelines)
library(mlr3learners)
library(mlr3extralearners)

dml_grf_att <- function(outcome, treatment, covariates, dataset, 
                    paper, model,  seed = 123){
  set.seed(seed)
  
  dataset <- filter(dataset, !is.na(!!sym(outcome))) %>%
    select(all_of(c(treatment, outcome, covariates)))
  
  y <- as.numeric(dataset[[outcome]])
  X <- model_matrix(~., select(dataset, all_of(covariates)))[,]
  d <- as.numeric(dataset[[treatment]])
  
  grf_model <- grf::causal_forest(X = X, Y = y, W = d, seed = 123)
  
  grf_out <- grf::average_treatment_effect(grf_model, target.sample = 'treated')

  
  
  
  # dataset_drop_na$cov_mean <- dataset_drop_na %>%
  #   select(all_of(covariates_design)) %>%
  #   mutate_all(scale) %>%
  #   apply(1, mean)


  # dml_dataframe <- as.data.frame(cbind(y, d, 
  #                                      d_bar = dataset_drop_na[[paste0('mean_', treatment)]],
  #                                      as_tibble(X)[,-1], 
  #                                      as_tibble(mean_X)[,-1], 
  #                                      cluster = dataset_drop_na[[clustervar]]))
  
  
  graph_ensemble_regr = gunion(list(
      po("learner", lrn("regr.cv_glmnet", s = "lambda.min")),
      po("learner", lrn('regr.xgboost', max_depth = 4)),
      po("learner", lrn("regr.glm"))
    )) %>>%
      po("regravg", 3)
  
  ensemble_pipe_regr = as_learner(graph_ensemble_regr)
  
  # DML
  set.seed(seed)
  dml_data <- double_ml_data_from_data_frame(dataset,
                                             x_cols = covariates,
                                             y_col = outcome,
                                             d_cols = treatment)
  
  # y <- as.numeric(dataset_drop_na[[outcome]])
  # # X <- select(dataset_drop_na, covariates_design)
  # X <- model_matrix(~., select(dataset_drop_na, all_of(covariates)))[,]
  # # mean_X <- model_matrix(~., select(dataset_drop_na, all_of(paste0('mean_', covariates))))[,]
  # d <- as.numeric(dataset_drop_na[[treatment]])
  # 
  # dml_data <- double_ml_data_from_matrix(X = X, y = y, d = d, 
  #                                        cluster_vars = dataset_drop_na[[clustervar]])
  
  # dml_data <- double_ml_data_from_matrix(X = select(dataset_drop_na, all_of(covariates_design)),
  #                                            y = dataset_drop_na[,outcome],
  #                                            d = dataset_drop_na[,treatment],
  #                                            cluster_vars = dataset_drop_na[,clustervar])
  obj_dml_plr_sim_pipe_ensemble = DoubleML::DoubleMLIRM(dml_data, score = 'ATTE',
                                                  ml_l = ensemble_pipe_regr,
                                                  ml_m = ensemble_pipe_regr)
  obj_dml_plr_sim_pipe_ensemble$fit() 
  dml_out <- data.frame(estimate = obj_dml_plr_sim_pipe_ensemble$coef,
                         std.error = obj_dml_plr_sim_pipe_ensemble$se)
  
  
  return(list(grf = grf_out, 
              dml = dml_out))
}

unemp_func <- function(x){
  x %>%
    as.data.frame() %>%
    mutate(re74_0 = re74 == 0,
         re75_0 = re75 == 0) 
}

lalonde_exp <- read_dta(here('data', 'nsw.dta')) %>%
  as.data.frame() %>%
  mutate(re75_0 = re75 == 0)
lalonde_exp_74 <- read_dta(here('data', 'nsw_dw.dta')) %>%
  unemp_func()
lalonde_cps1_controls <- read_dta(here('data', 'cps_controls.dta')) %>%
  unemp_func()
lalonde_cps3_controls <- read_dta(here('data', 'cps_controls3.dta')) %>%
  unemp_func()
lalonde_psid1_controls <- read_dta(here('data', 'psid_controls.dta')) %>%
  unemp_func()
lalonde_psid3_controls <- read_dta(here('data', 'psid_controls3.dta')) %>%
  unemp_func()


lalonde_exp_models <- dml_grf_att(outcome = 're78', 
        treatment = 'treat', 
        covariates = c('age', 'education', 'black', 'hispanic', 'married', 'nodegree', 're75', 're75_0'),
        dataset = lalonde_exp,
        paper = 'NSW',
        model = 'experimental')

```




```{r lalonde, eval = F, fig.height = 8, fig.cap = 'ATE estimates and 95-percent bootstrap standard error confidence intervals for Lalonde NSW data as provided by Dehejia and Wahba (1999), with CPS and PSID comparison groups. Standard errors shown in parentheses. Covariates include age, education in years of schooling, earnings in 1975, and dichotomous variables for Black and Hispanic race, married, not having a high school degree, and having no earnings in 1975. The "With 1974 earnings" estimates additionally include earnings in 1974 as a covariate, along with an indicator for having no earnings in 1974.'}
# lalonde_means <- read_csv(here('files', 'lalonde_means.csv'))

lalonde_results <- sim_results %>%
  mutate(set = ifelse(set == 'lalondeCPS-3 74', 'lalonde CPS-3 74', set),
         set = ifelse(set == 'lalondeCPS-3 original', 'lalonde CPS-3 original', set)) %>%
  filter(str_detect(set, 'lalonde')) %>%
  # filter(str_detect(set, 'experimental') | str_detect(set, 'PSID-3')) %>%
  group_by(set, method_estimator, method, estimator) %>%
  summarize(se = sd(ate),
            estimate = mean(ate)) %>%
  ungroup() %>%
  # left_join(select(lalonde_means, estimate = ate, method, estimator, set)) %>%
  separate_wider_delim(set, delim = ' ', names = c('set', 'sample', 'include_74')) %>%
  mutate(sample = str_replace(sample, 'experimental', 'Experimental'),
         sample = factor(sample, levels = c('Experimental', 'CPS-1', 'CPS-3', 'PSID-1', 'PSID-3')),
         # estimator = factor(estimator, levels = c('ols_logit', 'ols', 'logit', 'grf', 'superlearner')),
         # method = factor(method, levels = c('ols', 'psm','ipw', 'g-comp', 'lin', 'aipw', 'tmle', 'dml')),
         include_74 = ifelse(include_74 == '74', 'With 1974 earnings', 'Original LaLonde sample'),
         lower = estimate - 1.96*se, 
         upper = estimate + 1.96*se) 



            # lower = quantile(ate, .0275),
            # upper = quantile(ate, .975))
            # upper = estimate + 1.96*sd(ate),
            # lower = estimate - 1.96*sd(ate))

lalonde_results %>%
  mutate(method_estimator = str_replace(method_estimator, 'superlearner', 'superl.')) %>%
  mutate(method_estimator = factor(method_estimator, levels = unique({.$method_estimator}))) %>%
  ggplot(aes(x = sample, y = estimate, color = include_74, shape = include_74)) +
  geom_pointrange(aes(ymin = lower, ymax = upper), position = position_dodge(width = .5), size = .3) +
  geom_hline(yintercept = 0) +
  facet_wrap(~method_estimator) +
  labs(x = '', y = '') +
  coord_cartesian(ylim = c(-5000, 5000)) +
  theme(axis.text.x=element_text(angle=90, hjust=0.95,vjust=0.3),
        legend.position = 'bottom')  +
  labs(title = 'Results for Lalonde NSW data, with CPS and PSID comparison groups')

ggsave(here('draft/figures', 'lalonde.png'), width = 18,  height = 8, dpi = 1200)
```


<!-- As another evaluation of these methods, I use data from LaLonde's [-@lalonde_1986_evaluating] study of the National Supported Work Demonstration (NSW), as provided by @dehejia_1999_causal. Between March 1975 and July 1977, the NSW randomly provided training to disadvantaged workers. LaLonde used earnings in 1978 as the outcome of interest; comparing earnings in this year for treated and untreated workers allows an experimental estimate of the effect of the intervention. Restricting the sample to men, this study had `r nrow(filter(lalonde_exp, treat == T))` treated and `r nrow(filter(lalonde_exp, treat == F))` control participants. Covariates include age, education in years of schooling, earnings in 1975, and dichotomous variables for Black and Hispanic race, married, and not having a high school degree. Following @dehejia_1999_causal, I add a variable indicating whether each respondent's earnings in 1975 was $0 -- i.e., they were unemployed.      -->

<!-- LaLonde compared these experimental estimates to control samples drawn from the Panel Study of Income Dynamics (PSID) and Westat's Matched Current Population Survey-Social Security Administration File (CPS). The PSID-1 sample (*n* = `r nrow(lalonde_psid1_controls)`) contains all male household heads under 55 who did not classify themselves as retired in 1975, and the PSID-3 sample (*n* = `r nrow(lalonde_psid3_controls)`) further restricts this to men who were not working in the spring of 1976 or 1975. The CPS-1 sample (*n* = `r nrow(lalonde_cps1_controls)`) includes all CPS males under 55, and CPS-3 (*n* = `r nrow(lalonde_cps3_controls)`) restricts this two those who were not working in March 1976 whose earnings in 1975 were below the poverty level. Restricting these observational samples gets closer to the group eligible for the NSW.   -->

<!-- Following @dehejia_1999_causal, I present results for the original samples analyzed by @lalonde_1986_evaluating, but I also include results using a subsample of the experimental group that has 1974 earnings data available (`r nrow(filter(lalonde_exp_74, treat == T))` treated and `r nrow(filter(lalonde_exp_74, treat == F))` control participants) and include this additional covariate, along with an indicator variable for no earnings in 1974.   -->

<!-- Results are presented in Figure \@ref(fig:lalonde), with a table in the Appendix (Table  -->
<!-- \@ref(tab:lalonde-all)). Standard errors are based on 100 bootstrap samples. We first focus on the original LaLonde dataset, which did not include 1974 earnings. The "experimental" estimates provide a baseline for the comparison, suggesting that the program resulted in an earnings gain of about \$800. Some methods calculate widely different results for the experimental estimates, highlighting their instability. Echoing results from the simulations, methods that include logit models are particularly unstable.   -->

<!-- If selection on observables holds, then we should be able to recover experimental estimates from the non-experimental control groups. Most of the methods do not perform very well, estimating treatment effects with the wrong sign. The exception is in the PSID-3 sample, where 12 of the 17 methods estimate treatment effects with the correct (positive) sign. This sample is chosen to be closer to the experimental sample.  -->

<!-- Including 1974 earnings data results in much better estimates with the observational control groups. OLS, PSM, G-computation (SuperLearner), AIPW (SuperLearner), TMLE (SuperLearner), and DML (OLS/logit) compute fairly stable estimates across the samples. On the other hand, the estimates produced by IPW (logit), IPW (GRF), IPW (SuperLearner), the Lin estimator, and DML (GRF) vary widely across samples.    -->

<!-- These results highlight the importance of selection on observables holding. Without including 1974 earnings as a covariate, it appears that selection on observables does not hold, as most methods provide highly inaccurate estimates with the wrong sign. Once 1974 earnings are included, most of the methods provide estimates much closer to the experimental values.  -->

<!-- \newpage -->

```{r lalonde-all, eval = F}
# lalonde_results <- sim_results %>%
#   mutate(set = ifelse(set == 'lalondeCPS-3 74', 'lalonde CPS-3 74', set),
#          set = ifelse(set == 'lalondeCPS-3 original', 'lalonde CPS-3 original', set)) %>%
#   filter(str_detect(set, 'lalonde')) %>%
#   separate_wider_delim(set, delim = ' ', names = c('set', 'sample', 'include_74')) %>%
#   mutate(sample = factor(sample, levels = unique({.$sample})),
#          include_74 = ifelse(include_74 == 'original', 'No', "Yes"))
  

lalonde_results %>%
  mutate(include_74 = ifelse(include_74 == 'With 1974 earnings', 'Yes', 'No')) %>%
  # group_by(set, sample, include_74, method_estimator) %>%
  # summarize(estimate = mean(ate),
  #           se = sd(ate)) %>%
  # ungroup() %>%
  mutate(value = paste0(round(estimate), ' (', round(se), ')')) %>%
  select(`'74 earnings?` = include_74, Sample = sample, Method = method_estimator, value) %>%
  arrange(Sample) %>%
  pivot_wider(values_from = value, names_from = Sample) %>%
  arrange(`'74 earnings?`, Method) %>%
  mutate(Method = str_replace(Method, 'superlearner', 'superl.')) %>%
  kableExtra::kable(booktabs = T, 
                    # digits = 3,
                    linesep = '',
                    caption = 'ATE estimates for Lalonde NSW data as provided by Dehejia and Wahba (1999), with CPS and PSID comparison groups. Bootstrap standard errors shown in parentheses. Covariates include age, education in years of schooling, earnings in 1975, and dichotomous variables for Black and Hispanic race, married, not having a high school degree, and having no earnings in 1975. The "With 1974 earnings" estimates additionally include earnings in 1974 as a covariate, along with an indicator for having no earnings in 1974.') %>%
  kable_styling(latex_options = c("hold_position")) 
```

```{r lalonde-traditional, eval = F}
lalonde_results <- sim_results %>%
  mutate(set = ifelse(set == 'lalondeCPS-3 74', 'lalonde CPS-3 74', set),
         set = ifelse(set == 'lalondeCPS-3 original', 'lalonde CPS-3 original', set)) %>%
  filter(str_detect(set, 'lalonde')) %>%
  separate_wider_delim(set, delim = ' ', names = c('set', 'sample', 'include_74')) %>%
  mutate(sample = factor(sample, levels = unique({.$sample})),
         estimator = factor(estimator, levels = c('ols_logit', 'ols', 'logit', 'grf', 'superlearner')),
         method = factor(method, levels = c('ols', 'psm','ipw', 'g-comp', 'lin', 'aipw', 'tmle', 'dml')))
  

lalonde_results_df <- lalonde_results %>%
  group_by(set, sample, include_74, method_estimator) %>%
  summarize(estimate = mean(ate),
            se = sd(ate)) %>%
  ungroup() %>%
  mutate(value = paste0(round(estimate), ' (', round(se), ')')) %>%
  select(include_74, sample, method_estimator, value) %>%
  pivot_wider(values_from = value, names_from = method_estimator) %>%
  arrange(desc(include_74))

lalonde_results_df %>%
  select(include_74:`lin`) %>%
  kableExtra::kable(booktabs = T, 
                    # digits = 3,
                    # linesep = '',
                    caption = 'Traditional methods: ATE estimates for Lalonde NSW data as provided by Dehejia and Wahba (1999), with CPS and PSID comparison groups. Bootstrap standard errors shown in parentheses. Covariates include age, education in years of schooling, earnings in 1975, and dichotomous variables for Black and Hispanic race, married, not having a high school degree, and having no earnings in 1975. The "With 1974 earnings" estimates additionally include earnings in 1974 as a covariate, along with an indicator for having no earnings in 1974.') %>%
  kable_styling(latex_options = c("hold_position")) 
```

\newpage


# Main Simulations

```{r dorie-results-table}
sim_results %>%
  # bind_rows(mutate(aipw_df, method = as.factor('aipw (original)'))) %>%
  filter(set == 'main') %>%
  group_by(estimator, method) %>%
  summarize(bias = round(mean(ate - truth, na.rm = T), 3),
            # var = round(var(ate, na.rm = T), 3),
            percent_bias = bias/sd(ate, na.rm = T),
            rmse = round(sqrt(mean((ate - truth)^2, na.rm = T)), 3),
            mae = median(abs(ate - truth), na.rm = T),
            comp_time = median(comp_time),
            fail_count = n() - sum(!is.na(ate))
              ) %>%
  select(method, everything()) %>%
  arrange(method, estimator) %>% 
  # mutate(bias = as.character(bias),
  #        rmse = as.character(rmse)) %>%
  # mutate(across(bias:comp_time, function(x){as.character(round(x, 3))})) %>%
  kableExtra::kable(booktabs = T, 
                    digits = 3,
                    linesep = '',
                    caption = 'Main datasets: Results of Monte Carlo simulations using the first 20 DGPs from Dorie et al. (2019), 10 replications each. Percent bias is calculated as the estimator\'s bias as a percentage of its standard error, rmse is root mean squared error, mae is median absolute error, and comp\\_time is median computation time measured in seconds for each dataset.') %>%
  kable_styling(latex_options = c("hold_position"))
```



\newpage

# Linear Simulations


```{r dorie-linear-results}
sim_results %>%
  filter(set == 'linear') %>%
  # bind_rows(mutate(aipw_df, method = as.factor('aipw (original)'))) %>%
  group_by(estimator, method) %>%
  summarize(bias = round(mean(ate - truth, na.rm = T), 3),
            percent_bias = bias/sd(ate, na.rm = T),
            rmse = round(sqrt(mean((ate - truth)^2, na.rm = T)), 3),
            mae = median(abs(ate - truth), na.rm = T),
            comp_time = median(comp_time),
            fail_count = n() - sum(!is.na(ate))
              ) %>%
  select(method, everything()) %>%
  arrange(method, estimator) %>%
  # mutate(across(bias:comp_time, function(x){as.character(round(x, 3))})) %>%
  kableExtra::kable(booktabs = T, 
                    digits = 3,
                    linesep = '',
                    caption = 'Linear DGPs: Results of Monte Carlo simulations using the two datasets from Dorie et al. (2019), with linear data generating processes, 100 replications each. Percent bias is calculated as the estimator\'s bias as a percentage of its standard error, rmse is root mean squared error, mae is median absolute error, and comp\\_time is median computation time measured in seconds for each dataset.') %>%
  kable_styling(latex_options = c("hold_position"))
```

\newpage

# Data Generating Processes

```{r dgp}
dgp_names <- c('Treat. assign.', 'Prob. of treat.',
               'Overlap', 'Response surface',
               'Alignment',
               'Treat. heterogeneity')

rename_vec <- names(aciccomp2016::parameters_2016)
names(rename_vec) <- dgp_names

sim_results_dgp <- sim_results %>%
  filter(set == 'main') %>%
  # mutate(paramter_num = ceiling(dataset/10)) %>%
  left_join(mutate(aciccomp2016::parameters_2016, dorie_dataset = row_number())) %>%
  rename(rename_vec) %>%
  mutate(estimator = if_else(is.na(estimator), 'NA', estimator),
         method_estimator = str_replace(method_estimator, 'superlearner', 'superl.')) %>%
  mutate(method_estimator = factor(method_estimator, levels = unique({.$method_estimator}))) 


dgp_list <- list()

for(name in dgp_names){
  
  dgp_list[[name]] <- sim_results_dgp %>%
    group_by(!!sym(name), method_estimator) %>%
    summarize(bias = round(mean(ate - truth, na.rm = T), 3),
            percent_bias = bias/sd(ate, na.rm = T),
            rmse = round(sqrt(mean((ate - truth)^2, na.rm = T)), 3),
            mae = median(abs(ate - truth), na.rm = T),
            datasets = n_distinct(dataset)
              )  %>%
    ungroup() %>%
    mutate(`DGP parameter` = name,
          dgp_value = as.character(!!sym(name))) %>%
    select(-!!sym(name))
  
}



bind_rows(dgp_list) %>%
  select(`DGP parameter`, dgp_value, everything()) %>%
  arrange(`DGP parameter`, dgp_value, rmse) %>%  
  # mutate(bias = as.character(bias),
  #        rmse = as.character(rmse)) %>%
  # mutate(across(bias:comp_time, function(x){as.character(round(x, 3))})) %>%
  kableExtra::kable(booktabs = T, 
                    digits = 3,
                    linesep = '',
                    longtable = T,
                    caption = 'Data generating process: Within each DGP value, estimates are sorted from lowest to highest RMSE, based on Monte Carlo simulations using the first 20 DGPs from Dorie et al. (2019), 10 replications each. Percent bias is calculated as the estimator\'s bias as a percentage of its standard error, rmse is root mean squared error, mae is median absolute error, and datasets shows the number of distinct datasets in the simulations with each particular DGP parameter.') %>%
  kable_styling(latex_options = c("hold_position")) #'repeat_header')) 
  
  
```

\newpage

# Sample Sizes

```{r dorie-results-size}
sim_results %>%
  filter(set %in% c('small', 'large')) %>% 
  group_by(estimator, method, size) %>%
  summarize(bias = round(mean(ate - truth, na.rm = T), 3),
            percent_bias = bias/sd(ate, na.rm = T),
            rmse = round(sqrt(mean((ate - truth)^2, na.rm = T)), 3),
            mae = median(abs(ate - truth), na.rm = T),
            comp_time = median(comp_time),
            fail_count = n() - sum(!is.na(ate))
              ) %>%
  select(method, everything()) %>%
  arrange(method, estimator, size) %>%  
  # mutate(bias = as.character(bias),
  #        rmse = as.character(rmse)) %>%
  # mutate(across(bias:comp_time, function(x){as.character(round(x, 3))})) %>%
  kableExtra::kable(booktabs = T, 
                    digits = 3,
                    linesep = '',
                    longtable = T,
                    caption = 'Sample size: Results of Monte Carlo simulations using DGP 7 from Dorie et al. (2019) with varying sample sizes, 20 replications each. Percent bias is calculated as the estimator\'s bias as a percentage of its standard error, rmse is root mean squared error, mae is median absolute error, and comp\\_time is median computation time measured in seconds for each dataset.') %>%
  kable_styling(latex_options = c("hold_position")) #'repeat_header')) 
```

\newpage


<!-- # Replications -->

<!-- ```{r aksoy, eval = F} -->
<!-- aksoy <- read_dta(here('replication', 'aksoy.dta')) %>% -->
<!--   mutate(cid_num = as.integer(factor(cid))) %>% -->
<!--   as_factor() -->

<!-- # first three models from table 2 -->

<!-- m1 <- lm(ISL ~ `_Y28` + `_Y32` + `_Y42` + `_Y46` + `_Y50` + `_Y54` + `_Y57` + `_Y62` +  -->
<!--      `_Y66` + `_Y70` + `_Y71` + dlen + cid, -->
<!--    data = filter(aksoy, electyr == T)) # %>% -->
<!--   # tidy() %>% -->
<!--   # filter(!str_detect(term, 'cid'), !str_detect(term, '_Y')) -->

<!-- m2 <- lm(ISL ~ `_Y28` + `_Y32` + `_Y42` + `_Y46` + `_Y50` + `_Y54` + `_Y57` + `_Y62` +  -->
<!--      `_Y66` + `_Y70` + `_Y71` + dlen + cid + gdp_g + t + m + pop, -->
<!--    data = aksoy)  -->
<!--   # tidy() %>% -->
<!--   # filter(!str_detect(term, 'cid'), !str_detect(term, '_Y')) -->

<!-- m3 <- lm(ISL ~ `_Y28` + `_Y32` + `_Y42` + `_Y46` + `_Y50` + `_Y54` + `_Y57` + `_Y62` +  -->
<!--      `_Y66` + `_Y70` + `_Y71` + dlen + cid + gdp_g + t + m + pop + l_ISL, -->
<!--    data = aksoy)  -->
<!--   # tidy() %>% -->
<!--   # filter(!str_detect(term, 'cid'), !str_detect(term, '_Y')) -->

<!-- # aksoy %>% -->
<!-- #   filter(electyr == T) %>% -->
<!-- #   mutate(across(c(`_Y28`, `_Y32`, `_Y42`, `_Y46`, `_Y50`, `_Y54`, `_Y57`,  -->
<!-- #                   `_Y62`, `_Y66`, `_Y70`, `_Y71`), ~ .x - mean(.x, na.rm = T))) %>% -->
<!-- #   estimatr::lm_robust(ISL ~ dlen*(`_Y28` + `_Y32` + `_Y42` + `_Y46` + `_Y50` +  -->
<!-- #                                     `_Y54` + `_Y57` + `_Y62` + `_Y66` + `_Y70` + `_Y71` + cid), -->
<!-- #    data = .) %>% -->
<!-- #   tidy() %>% -->
<!-- #   filter(term == 'dlen') -->
<!-- #  -->
<!-- #  -->
<!-- # m1_lin <- estimatr::lm_robust(ISL ~ dlen*(`_Y28` + `_Y32` + `_Y42` + `_Y46` + `_Y50` + `_Y54` + `_Y57` + `_Y62` + `_Y66` + `_Y70` + `_Y71`) + cid, -->
<!-- #    data = filter(aksoy, electyr == T)) %>% -->
<!-- #   tidy() %>% -->
<!-- #   filter(term == 'dlen') -->
<!-- #  -->
<!-- #  -->
<!-- # m1_lin <- lm_lin_continuous(ISL ~ dlen, -->
<!-- #                            covariates = ~ `_Y28` + `_Y32` + `_Y42` + `_Y46` + `_Y50` + `_Y54` + `_Y57` + `_Y62` + -->
<!-- #      `_Y66` + `_Y70` + `_Y71` + cid, -->
<!-- #    data = filter(aksoy, electyr == T)) %>% -->
<!-- #   tidy() %>% -->
<!-- #   filter(term == 'dlen') -->
<!-- #  -->
<!-- #  -->
<!-- # m2_lin <- lm_lin_continuous(ISL ~ dlen, -->
<!-- #                            covariates = ~ `_Y28` + `_Y32` + `_Y42` + `_Y46` + `_Y50` + `_Y54` + `_Y57` + `_Y62` + -->
<!-- #      `_Y66` + `_Y70` + `_Y71` + cid + gdp_g + t + m + pop, -->
<!-- #    data = aksoy) %>% -->
<!-- #   tidy() %>% -->
<!-- #   filter(term == 'dlen')  -->
<!-- #  -->
<!-- #  -->
<!-- # m3_lin <- lm_lin_continuous(ISL ~ dlen, -->
<!-- #                            covariates = ~ `_Y28` + `_Y32` + `_Y42` + `_Y46` + `_Y50` + `_Y54` + `_Y57` + `_Y62` + -->
<!-- #      `_Y66` + `_Y70` + `_Y71` + dlen + cid + gdp_g + t + m + pop + l_ISL, -->
<!-- #    data = aksoy) %>% -->
<!-- #   tidy() %>% -->
<!-- #   filter(term == 'dlen')  -->




<!-- # aksoy_drop_na_y <- filter(aksoy, !is.na(ISL)) -->





<!-- m1_grf_dml <- dml_grf(outcome = 'ISL',  -->
<!--         treatment = 'dlen',  -->
<!--         covariates = c('year'),  -->
<!--         clustervar = 'cid_num', -->
<!--         dataset = aksoy, -->
<!--         target = 'all') -->


<!-- m2_grf_dml <- dml_grf(outcome = 'ISL',  -->
<!--         treatment = 'dlen',  -->
<!--         covariates = c('year', 'gdp_g', 't', 'm', 'pop'),  -->
<!--         clustervar = 'cid_num', -->
<!--         dataset = aksoy, -->
<!--         target = 'all') -->

<!-- m3_grf_dml <- dml_grf(outcome = 'ISL',  -->
<!--         treatment = 'dlen',  -->
<!--         covariates = c('year', 'gdp_g', 't', 'm', 'pop', 'l_ISL'),  -->
<!--         clustervar = 'cid_num', -->
<!--         dataset = aksoy, -->
<!--         target = 'all') -->



<!-- m1 <- data.frame(estimate = 7.159, std.error = 2.539) -->
<!-- m2 <- data.frame(estimate = 7.349, std.error = 2.491) -->
<!-- m3 <- data.frame(estimate = 5.317, std.error = 1.855) -->

<!-- compare_tbl(list(append(list(original = m1), m1_grf_dml),  -->
<!--                                   append(list(original = m2), m2_grf_dml),  -->
<!--                                   append(list(original = m3), m3_grf_dml)), -->
<!--                              tidy = F) %>% -->
<!--   write_rds(here('replication', 'aksoy_rep.RDS')) -->


<!-- # huxtable::huxreg(compare_tbl(list(append(list(original = m1), m1_grf_dml),  -->
<!-- #                                   append(list(original = m2), m2_grf_dml),  -->
<!-- #                                   append(list(original = m3), m3_grf_dml)), -->
<!-- #                              tidy = F), -->
<!-- #                  statistics = NA) %>% -->
<!-- #   huxtable::insert_row(c('Covariates', 'No', rep('Yes', 2)), after = nrow(.) - 1) %>% -->
<!-- #   huxtable::insert_row(c('Lagged dependent variable', 'No', 'No', 'Yes'), after = nrow(.) - 1) %>% -->
<!-- #   huxtable::set_caption('Replication of aksoy et al. (2022) Table 2, models for outcome of Islamic Votes: "Effect of Fasting Hours (Daylength) during Ramadan on Various Outcome Variables Based on Regression Models That Include Fixed Effects for Provinces and Election Years"') %>% -->
<!-- #   write_rds(here('replication', 'aksoy_tab.RDS')) -->
<!-- #  -->
<!-- # read_rds(here('replication', 'aksoy_rep.RDS')) %>% -->
<!-- #   huxtable::huxreg() -->





<!-- ``` -->


<!-- ```{r biegert, eval = F} -->
<!-- # Table 3 -->

<!-- biegert <- read_dta(here('replication', 'biegert.dta')) %>% -->
<!--   filter(sampleC == 1) %>% -->
<!--   mutate(year_num = as.numeric(year), -->
<!--          allstar_y_num = as.numeric(allstar_y), -->
<!--          allstar_x_num = as.numeric(allstar_x), -->
<!--     across(c(allstar_y, allstar_x, year), as.factor), -->
<!--     player_id_num = as.integer(factor(player_id))) %>% -->
<!--   as_factor() -->

<!-- m1 <- glm(allstar_y ~ allstar_x,  -->
<!--           data = filter(biegert, sampleC == 1), family = 'binomial') %>% -->
<!--   margins::margins(variables = 'allstar_x',  -->
<!--                    vcov = sandwich::vcovCL(., cluster = ~player_id))  -->

<!-- m2 <- glm(allstar_y ~ allstar_x + height + pos + age_0 + age_0_2 + Black + time + time_2 + year,  -->
<!--           data = filter(biegert, sampleC == 1), -->
<!--           family = binomial(link = 'logit')) %>% -->
<!--   margins::margins(variables = 'allstar_x',  -->
<!--                    vcov = sandwich::vcovCL(., cluster = ~player_id))  -->

<!-- m3 <- glm(allstar_y ~ allstar_x + height + pos + age_0 + age_0_2 + Black + time + time_2 + year + -->
<!--             pts_sdt_nd + ast_sdt_nd + trb_sdt_nd + min_played_nd +  playoffs_nd + win_nd + bigm_nd,  -->
<!--           data = filter(biegert, sampleC == 1), -->
<!--           family = binomial(link = 'logit')) %>% -->
<!--   margins::margins(variables = 'allstar_x',  -->
<!--                    vcov = sandwich::vcovCL(., cluster = ~player_id))  -->

<!-- m4 <- glm(allstar_y ~ allstar_x + height + pos + age_0 + age_0_2 + Black + time + time_2 + year + -->
<!--             pts_sdt_nd + ast_sdt_nd + trb_sdt_nd + min_played_nd +  playoffs_nd + win_nd + bigm_nd + -->
<!--             pts_sdt_t + ast_sdt_t + trb_sdt_t,  -->
<!--           data = filter(biegert, sampleC == 1), -->
<!--           family = binomial(link = 'logit')) %>% -->
<!--   margins::margins(variables = 'allstar_x',  -->
<!--                    vcov = sandwich::vcovCL(., cluster = ~player_id))  -->

<!-- m5 <- glm(allstar_y ~ allstar_x + height + pos + age_0 + age_0_2 + Black + time + time_2 + year + -->
<!--             pts_sdt_nd + ast_sdt_nd + trb_sdt_nd + min_played_nd +  playoffs_nd + win_nd + bigm_nd + -->
<!--             pts_sdt_t + ast_sdt_t + trb_sdt_t + -->
<!--             min_played_t + playoffs_t + win_t + bigm_t,  -->
<!--           data = filter(biegert, sampleC == 1), -->
<!--           family = binomial(link = 'logit')) %>% -->
<!--   margins::margins(variables = 'allstar_x',  -->
<!--                    vcov = sandwich::vcovCL(., cluster = ~player_id))  -->

<!-- m6 <- glm(allstar_y ~ allstar_x + allstar_hi + height + pos + age_0 + age_0_2 + Black + time + time_2 + year + -->
<!--             pts_sdt_nd + ast_sdt_nd + trb_sdt_nd + min_played_nd +  playoffs_nd + win_nd + bigm_nd + -->
<!--             pts_sdt_t + ast_sdt_t + trb_sdt_t + -->
<!--             min_played_t + playoffs_t + win_t + bigm_t + -->
<!--             pts_sdt_hi + ast_sdt_hi + trb_sdt_hi + min_played_hi + playoffs_hi + win_hi + bigm_hi,  -->
<!--           data = filter(biegert, sampleC == 1), -->
<!--           family = binomial(link = 'logit')) %>% -->
<!--   margins::margins(variables = 'allstar_x',  -->
<!--                    vcov = sandwich::vcovCL(., cluster = ~player_id))  -->





<!-- # M1  -->
<!-- set.seed(123) -->
<!-- Y <- as.numeric(biegert[['allstar_y']]) -->
<!-- X <- data.frame(var = rep(NA_integer_, length(Y))) -->
<!-- W <- as.numeric(biegert[['allstar_x']]) -->

<!-- grf_model1 <- grf::causal_forest(X = X, Y = Y, W = W, seed = 123, -->
<!--                       clusters = biegert$player_id_num -->
<!--                       ) -->

<!-- grf_out1 <- grf::average_treatment_effect(grf_model1, target.sample = 'all') -->


<!-- dml_out1 <- data.frame(estimate = NA, -->
<!--                        std.error = NA) -->
<!-- dml_cre_out1 <- dml_out1 -->
<!-- dml_hybrid_out1 <- dml_out1 -->

<!-- # M2 -->
<!-- m2_grf_dml <- dml_grf(outcome = 'allstar_y_num',  -->
<!--         treatment = 'allstar_x_num',  -->
<!--         covariates = c('height', 'pos', 'age_0', 'Black', 'time', 'year_num'),  -->
<!--         clustervar = 'player_id_num', -->
<!--         dataset = biegert, -->
<!--         target = 'all') -->


<!-- # M3  -->
<!-- m3_grf_dml <- dml_grf(outcome = 'allstar_y_num',  -->
<!--         treatment = 'allstar_x_num',  -->
<!--         covariates = c('height', 'pos', 'age_0', 'Black', 'time', 'year_num', -->
<!--                        'pts_sdt_nd', 'ast_sdt_nd', 'trb_sdt_nd', 'min_played_nd',  'playoffs_nd', 'win_nd', 'bigm_nd'),  -->
<!--         clustervar = 'player_id_num', -->
<!--         dataset = biegert, -->
<!--         target = 'all') -->

<!-- # M4 -->
<!-- m4_grf_dml <- dml_grf(outcome = 'allstar_y_num',  -->
<!--         treatment = 'allstar_x_num',  -->
<!--         covariates = c('height', 'pos', 'age_0', 'Black', 'time', 'year_num', -->
<!--                        'pts_sdt_nd', 'ast_sdt_nd', 'trb_sdt_nd', 'min_played_nd',  'playoffs_nd', 'win_nd', 'bigm_nd', -->
<!--                        'pts_sdt_t', 'ast_sdt_t', 'trb_sdt_t'),  -->
<!--         clustervar = 'player_id_num', -->
<!--         dataset = biegert, -->
<!--         target = 'all') -->


<!-- # M5 -->
<!-- m5_grf_dml <- dml_grf(outcome = 'allstar_y_num',  -->
<!--         treatment = 'allstar_x_num',  -->
<!--         covariates = c('height', 'pos', 'age_0', 'Black', 'time', 'year_num', -->
<!--                        'pts_sdt_nd', 'ast_sdt_nd', 'trb_sdt_nd', 'min_played_nd',  'playoffs_nd', 'win_nd', 'bigm_nd', -->
<!--                        'pts_sdt_t', 'ast_sdt_t', 'trb_sdt_t', -->
<!--                        'min_played_t', 'playoffs_t', 'win_t', 'bigm_t'),  -->
<!--         clustervar = 'player_id_num', -->
<!--         dataset = biegert, -->
<!--         target = 'all') -->



<!-- # # M6 -->
<!-- # m6_grf_dml <- dml_grf(outcome = 'allstar_y_num',  -->
<!-- #         treatment = 'allstar_x_num',  -->
<!-- #         covariates = c('height', 'pos', 'age_0', 'Black', 'time', 'year_num', -->
<!-- #                        'pts_sdt_nd', 'ast_sdt_nd', 'trb_sdt_nd', 'min_played_nd',  'playoffs_nd', 'win_nd', 'bigm_nd', -->
<!-- #                        'pts_sdt_t', 'ast_sdt_t', 'trb_sdt_t', -->
<!-- #                        'min_played_t', 'playoffs_t', 'win_t', 'bigm_t', -->
<!-- #                        'pts_sdt_hi', 'ast_sdt_hi', 'trb_sdt_hi', 'min_played_hi', 'playoffs_hi', 'win_hi', 'bigm_hi'),  -->
<!-- #         clustervar = 'player_id_num', -->
<!-- #         dataset = biegert, -->
<!-- #         target = 'all') -->

<!-- out_empty <- grf_out1 -->
<!-- out_empty$estimate <- NA -->
<!-- out_empty$std.err <-  -->

<!-- compare_tbl(model_list = list( -->
<!--                  list(original = m1, grf = grf_out1, dml = dml_out1, dml_cre = dml_cre_out1, dml_wg_cre = dml_hybrid_out1),  -->
<!--                  append(list(original = m2), m2_grf_dml),  -->
<!--                  append(list(original = m3), m3_grf_dml), -->
<!--                  append(list(original = m4), m4_grf_dml), -->
<!--                  append(list(original = m5), m5_grf_dml), -->
<!--             treatment = 'allstar_x1', -->
<!--             tidy = T) %>% -->
<!--   write_rds(here('replication', 'biegert_rep.RDS')) -->


<!-- # Final table -->
<!-- # huxtable::huxreg(compare_tbl(list(list(m1, grf_out1, dml_out1), -->
<!-- #                                   list(m2, grf_out2, dml_out2), -->
<!-- #                                   list(m3, grf_out3, dml_out3), -->
<!-- #                                   list(m4, grf_out4, dml_out4), -->
<!-- #                                   list(m5, grf_out5, dml_out5), -->
<!-- #                                   list(m6, grf_out6, dml_out6)), -->
<!-- #                              treatment = 'allstar_x1'), -->
<!-- #                  statistics = NA) %>% -->
<!-- #   huxtable::insert_row(c('Baseline confounders', 'No', rep('Yes', 5)), after = nrow(.) - 1) %>% -->
<!-- #   huxtable::insert_row(c('Prior situation + performance', rep('No', 2), rep('Yes', 4)), after = nrow(.) - 1) %>% -->
<!-- #   huxtable::insert_row(c('Current performance', rep('No', 3), rep('Yes', 3)), after = nrow(.) - 1) %>% -->
<!-- #   huxtable::insert_row(c('Current situation', rep('No', 4), rep('Yes', 2)), after = nrow(.) - 1) %>% -->
<!-- #   huxtable::insert_row(c('Cumul. AS + cumul. mediators', rep('No', 5), 'Yes'), after = nrow(.) - 1) %>% -->
<!-- #   huxtable::set_caption('Replication of Biegert et al. (2023) Table 3: "Average Marginal Effects from Logistic Regression Models of All-Star Nomination"') %>% -->
<!-- #   write_rds(here('replication', 'biegert_tab.RDS')) -->
<!-- #  -->
<!-- # read_rds(here('replication', 'biegert_tab.RDS')) -->

<!-- ``` -->



<!-- ```{r nussio-ind, eval = F} -->
<!-- nussio_ind <- read_dta(here('replication/nussio_2024', 'Mexico City Individual data.dta')) %>% -->
<!--   filter(if_all(c(PARP, lognombre), ~!is.na(.x))) %>% -->
<!--   mutate(across(c(PARP, IT1, ED, BASURA), as.numeric), -->
<!--          cve_col_num = as.numeric(factor(cve_col))) %>% -->
<!--   as_factor() -->





<!-- ## Table 2 #### (individual analysis) -->

<!-- m1 <- lm(PARP ~ lognombre + IT1,  -->
<!--          nussio_ind) %>% -->
<!--   lmtest::coeftest(., vcov = sandwich::vcovCL(., ~cve_col)) -->

<!-- m2 <- lm(PARP ~ lognombre + IT1 +  -->
<!--            ED + age + female + INGi + unemployed,  -->
<!--          nussio_ind) %>% -->
<!--   lmtest::coeftest(., vcov = sandwich::vcovCL(., ~cve_col)) -->

<!-- m3 <- lm(PARP ~ lognombre + IT1 +  -->
<!--            ED + age + female + INGi + unemployed + -->
<!--            HER + catholic + nonreligious + working + BASURA + RESS +  -->
<!--            PELEA  + PADRES + index_trustgov,  -->
<!--          nussio_ind) %>% -->
<!--   lmtest::coeftest(., vcov = sandwich::vcovCL(., ~cve_col)) -->

<!-- m4 <- lm(PARP ~ lognombre + IT1 +  -->
<!--            ED + age + female + INGi + unemployed + -->
<!--            HER + catholic + nonreligious + working + BASURA + RESS +  -->
<!--            PELEA  + PADRES + index_trustgov + -->
<!--            col, nussio_ind) %>% -->
<!--   lmtest::coeftest(., vcov = sandwich::vcovCL(., ~cve_col))  -->
<!--   # tidy() %>% -->
<!--   # filter(!(str_detect(term, 'col'))) -->


<!-- # M1  -->
<!-- m1_grf_dml <- dml_grf(outcome = 'PARP',  -->
<!--         treatment = 'lognombre',  -->
<!--         covariates = c('IT1'),  -->
<!--         clustervar = 'cve_col_num', -->
<!--         dataset = nussio_ind, -->
<!--         target = 'all') -->

<!-- # M2  -->
<!-- m2_grf_dml <- dml_grf(outcome = 'PARP',  -->
<!--         treatment = 'lognombre',  -->
<!--         covariates = c('IT1', 'ED', 'age', 'female', 'INGi', 'unemployed'),  -->
<!--         clustervar = 'cve_col_num', -->
<!--         dataset = nussio_ind, -->
<!--         target = 'all') -->

<!-- # M3 & M4 (M4 has fixed effects) -->
<!-- m3_grf_dml <- dml_grf(outcome = 'PARP',  -->
<!--         treatment = 'lognombre',  -->
<!--         covariates = c('IT1', 'ED', 'age', 'female', 'INGi', 'unemployed', -->
<!--                        'HER', 'catholic', 'nonreligious', 'working', 'BASURA', 'RESS',  -->
<!--                        'PELEA' , 'PADRES', 'index_trustgov'),  -->
<!--         clustervar = 'cve_col_num', -->
<!--         dataset = nussio_ind, -->
<!--         target = 'all') -->

<!-- m4_grf_dml <- m3_grf_dml -->


<!-- compare_tbl(model_list = list(append(list(original = m1), m1_grf_dml), -->
<!--                               append(list(original = m2), m2_grf_dml),  -->
<!--                               append(list(original = m3), m3_grf_dml), -->
<!--                               append(list(original = m4), m4_grf_dml)), -->
<!--             treatment = 'lognombre', -->
<!--             tidy = T) %>% -->
<!--   write_rds(here('replication', 'nussio_ind_rep.RDS')) -->


<!-- # Final table -->
<!-- # huxtable::huxreg(compare_tbl(list(list(m1, grf_out1, dml_out1), -->
<!-- #                                   list(m2, grf_out2, dml_out2), -->
<!-- #                                   list(m3, grf_out3, dml_out3), -->
<!-- #                                   list(m4, grf_out4, dml_out4)), -->
<!-- #                              treatment = 'lognombre'), -->
<!-- #                  statistics = NA) %>% -->
<!-- #   huxtable::insert_row(c('Colonia FE', 'No', 'No', 'No', 'Yes'), after = nrow(.) - 1) %>% -->
<!-- #   huxtable::insert_row(c('Control variables', 'No', 'Some', 'All', 'All'), after = nrow(.) - 1) %>% -->
<!-- #   huxtable::set_caption('Replication of Nussio (2024) Table 2: "Individual-Level Analysis: Community Ties and Lynching Participation"') %>% -->
<!-- #   write_rds(here('replication', 'nussio_ind_tab.RDS')) -->
<!-- #  -->
<!-- # read_rds(here('replication', 'nussio_ind_tab.RDS')) -->
<!-- ``` -->

<!-- ```{r nussio-ag, eval = F} -->
<!-- ## Table 4 #### (aggregate analysis) -->
<!-- nussio_ag <- read_dta(here('replication/nussio_2024',  -->
<!--                            'Mexico Municipality Cross-Sectional Data.dta')) %>% -->
<!--   filter(if_all(c(loglynchpermio, organized_lighting_mean), ~!is.na(.x))) %>% -->
<!--   mutate(estado_num = as.numeric(estado)) %>% -->
<!--   # mutate(across(c(PARP, IT1, ED, BASURA), as.numeric), -->
<!--   #        cve_col_num = as.integer(factor(cve_col))) %>% -->
<!--   as_factor() -->

<!-- nussio_ag_drop_na <- nussio_ag %>% drop_na(loglynchpermio, organized_lighting_mean, -->
<!--                           trust_neighbors_mean, problem_lighting_mean, -->
<!--                           c_poptot, area, pconeval_poverty_pobreza_pob,  -->
<!--                           coneval_gini_coeficientedegini, -->
<!--                           indigenous, c_poptot_norelpop, homirate, robberyrate, -->
<!--            victim_household_before_prev_yea, trust_army_mean) -->

<!-- m1 <- lm(loglynchpermio ~ organized_lighting_mean + trust_neighbors_mean + problem_lighting_mean, -->
<!--          nussio_ag) %>% -->
<!--   lmtest::coeftest(., vcov = sandwich::vcovCL(., ~estado)) -->

<!-- m2 <- lm(loglynchpermio ~ organized_lighting_mean + trust_neighbors_mean + problem_lighting_mean + -->
<!--            c_poptot + area + pconeval_poverty_pobreza_pob + coneval_gini_coeficientedegini +  -->
<!--            indigenous + c_poptot_norelpop + homirate + robberyrate, -->
<!--          nussio_ag) %>% -->
<!--   lmtest::coeftest(., vcov = sandwich::vcovCL(., ~estado)) -->

<!-- m3 <- lm(loglynchpermio ~ organized_lighting_mean + trust_neighbors_mean + problem_lighting_mean + -->
<!--            c_poptot + area + pconeval_poverty_pobreza_pob + coneval_gini_coeficientedegini +  -->
<!--            indigenous + c_poptot_norelpop + homirate + robberyrate + -->
<!--            victim_household_before_prev_yea + trust_army_mean, -->
<!--          nussio_ag) %>% -->
<!--   lmtest::coeftest(., vcov = sandwich::vcovCL(., ~estado)) -->

<!-- m4 <- lm(loglynchpermio ~ organized_lighting_mean + trust_neighbors_mean + problem_lighting_mean + -->
<!--            c_poptot + area + pconeval_poverty_pobreza_pob + coneval_gini_coeficientedegini +  -->
<!--            indigenous + c_poptot_norelpop + homirate + robberyrate + -->
<!--            victim_household_before_prev_yea + trust_army_mean +  -->
<!--            estado, -->
<!--          nussio_ag) -->



<!-- # M1  -->
<!-- m1_grf_dml <- dml_grf(outcome = 'loglynchpermio',  -->
<!--         treatment = 'organized_lighting_mean',  -->
<!--         covariates = c('trust_neighbors_mean', 'problem_lighting_mean'),  -->
<!--         clustervar = 'estado_num', -->
<!--         dataset = nussio_ag, -->
<!--         target = 'all') -->


<!-- # M2 -->
<!-- m2_grf_dml <- dml_grf(outcome = 'loglynchpermio',  -->
<!--         treatment = 'organized_lighting_mean',  -->
<!--         covariates = c('trust_neighbors_mean', 'problem_lighting_mean', -->
<!--                        'c_poptot', 'area', 'pconeval_poverty_pobreza_pob', 'coneval_gini_coeficientedegini',  -->
<!--            'indigenous', 'c_poptot_norelpop', 'homirate', 'robberyrate'),  -->
<!--         clustervar = 'estado_num', -->
<!--         dataset = nussio_ag, -->
<!--         target = 'all') -->

<!-- # M3 -->
<!-- m3_grf_dml <- dml_grf(outcome = 'loglynchpermio',  -->
<!--         treatment = 'organized_lighting_mean',  -->
<!--         covariates = c('trust_neighbors_mean', 'problem_lighting_mean', -->
<!--                        'c_poptot', 'area', 'pconeval_poverty_pobreza_pob', 'coneval_gini_coeficientedegini',  -->
<!--            'indigenous', 'c_poptot_norelpop', 'homirate', 'robberyrate', -->
<!--            'victim_household_before_prev_yea', 'trust_army_mean'),  -->
<!--         clustervar = 'estado_num', -->
<!--         dataset = nussio_ag, -->
<!--         target = 'all') -->

<!-- # M4 -->
<!-- m4_grf_dml <- m3_grf_dml -->


<!-- compare_tbl(model_list = list(append(list(original = m1), m1_grf_dml), -->
<!--                               append(list(original = m2), m2_grf_dml),  -->
<!--                               append(list(original = m3), m3_grf_dml), -->
<!--                               append(list(original = m4), m4_grf_dml)), -->
<!--             treatment = 'organized_lighting_mean', -->
<!--             tidy = T) %>% -->
<!--   write_rds(here('replication', 'nussio_ag_rep.RDS')) -->


<!-- # huxtable::huxreg(compare_tbl(list(list(m1, grf_out1, dml_out1), -->
<!-- #                                   list(m2, grf_out2, dml_out2), -->
<!-- #                                   list(m3, grf_out3, dml_out3), -->
<!-- #                                   list(m4, grf_out4, dml_out4)), -->
<!-- #                  treatment = 'organized_lighting_mean'), -->
<!-- #                  statistics = NA) %>% -->
<!-- #   huxtable::insert_row(c('Control variables', 'No', 'Some', 'All', 'All'), after = nrow(.) - 1) %>% -->
<!-- #   huxtable::insert_row(c('Estado FE', 'No', 'No', 'No', 'Yes'), after = nrow(.) - 1) %>% -->
<!-- #   huxtable::insert_row(c('Estado clustered SE', 'Yes', 'Yes', 'Yes', 'No'), after = nrow(.) - 1) %>% -->
<!-- #   huxtable::set_caption('Replication of Nussio (2024) Table 4: "Aggregate-Level Analysis: Community Ties and Lynching Rate"') %>% -->
<!-- #   # huxtable::set_width(1) %>% -->
<!-- #   # huxtable::set_all_padding(0) %>% -->
<!-- #   write_rds(here('replication', 'nussio_ag_tab.RDS')) -->
<!-- #  -->
<!-- # read_rds(here('replication', 'nussio_ag_tab.RDS')) -->

<!-- # names(grf_out1) <- c('estimate', 'std.error') -->
<!-- # tidy(m1) %>% -->
<!-- #   filter(term == 'organized_lighting_mean') %>% -->
<!-- #   bind_rows(mutate(bind_rows(grf_out1))) %>% -->
<!-- #   mutate(term = c('original', 'TMLE (GRF)'), p.value = p_val(estimate, std.error)) %>% -->
<!-- #   huxtable::huxreg() -->

<!-- ``` -->

<!-- ```{r nussio-ne, eval = F} -->
<!-- nussio_ne <- read_dta(here('replication/nussio_2024',  -->
<!--                            'Mexico Municipality Panel Data.dta')) %>% -->
<!--   # filter(if_all(c(loglynchpermio, organized_lighting_mean), ~!is.na(.x))) %>% -->
<!--   mutate(cve_num = as.numeric(cve), -->
<!--          year_num = year, -->
<!--          year = as.factor(year), -->
<!--          cve = cve, -->
<!--          cve = as.factor(cve)) %>% -->
<!--   # mutate(across(c(PARP, IT1, ED, BASURA), as.numeric), -->
<!--   #        cve_col_num = as.integer(factor(cve_col))) %>% -->
<!--   as_factor() -->

<!-- # m1 <- lm(lynch_event ~ eq2017_250X2017 + year + cve, data = nussio_ne) %>% -->
<!-- #   lmtest::coeftest(., vcov = sandwich::vcovCL(., ~cve)) -->

<!-- # m1 <- fixest::feols(lynch_event ~ eq2017_250X2017 | year + cve,  -->
<!-- #               data = nussio_ne) %>% -->
<!-- #   summary(vcov = ~cve) %>% -->
<!-- #   tidy() -->


<!-- m1 <- data.frame(estimate = 0.108, std.error = 0.019) -->
<!-- m2 <- data.frame(estimate = 0.113, std.error = 0.021) -->
<!-- m3 <- data.frame(estimate = 0.087, std.error = 0.019) -->
<!-- m4 <- data.frame(estimate = 0.126, std.error = 0.026) -->
<!-- m5 <- data.frame(estimate = -0.010, std.error = 0.002) -->
<!-- m6 <- data.frame(estimate = -0.009, std.error = 0.002) -->



<!-- # M1 -->
<!-- m1_grf_dml <- dml_grf(outcome = 'lynch_event',  -->
<!--         treatment = 'eq2017_250X2017',  -->
<!--         covariates = c('year_num'),  -->
<!--         clustervar = 'cve_num', -->
<!--         dataset = nussio_ne, -->
<!--         target = 'treated', -->
<!--         drop_na_grf = T) -->

<!-- # M2 -->
<!-- m2_grf_dml <- dml_grf(outcome = 'lynch_event',  -->
<!--         treatment = 'eq2017_250X2017',  -->
<!--         covariates = c('year_num', 'homicidefull', 'robofull', 'secuestrofull', 'inegi_infant_mort'),  -->
<!--         clustervar = 'cve_num', -->
<!--         dataset = nussio_ne, -->
<!--         target = 'treated', -->
<!--         drop_na_grf = T) -->

<!-- # M3 -->
<!-- m3_grf_dml <- dml_grf(outcome = 'lynch_event',  -->
<!--         treatment = 'eq2017_damageX2017',  -->
<!--         covariates = c('year_num'),  -->
<!--         clustervar = 'cve_num', -->
<!--         dataset = nussio_ne, -->
<!--         target = 'treated', -->
<!--         drop_na_grf = T) -->

<!-- # M4 -->
<!-- m4_grf_dml <- dml_grf(outcome = 'lynch_event',  -->
<!--         treatment = 'eq2017_damageX2017',  -->
<!--         covariates = c('year_num', 'homicidefull', 'robofull', 'secuestrofull', 'inegi_infant_mort'),  -->
<!--         clustervar = 'cve_num', -->
<!--         dataset = nussio_ne, -->
<!--         target = 'all', -->
<!--         drop_na_grf = T) -->

<!-- # # M5 -->
<!-- # m5_grf_dml <- dml_grf(outcome = 'lynch_event',  -->
<!-- #         treatment = 'eq2017_dist100X2017',  -->
<!-- #         covariates = c('year_num'),  -->
<!-- #         clustervar = 'cve_num', -->
<!-- #         dataset = nussio_ne, -->
<!-- #         target = 'all', -->
<!-- #         drop_na_grf = T) -->
<!-- #  -->
<!-- # # M6 -->
<!-- # m6_grf_dml <- dml_grf(outcome = 'lynch_event',  -->
<!-- #         treatment = 'eq2017_dist100X2017',  -->
<!-- #         covariates = c('year_num', 'homicidefull', 'robofull', 'secuestrofull', 'inegi_infant_mort'),  -->
<!-- #         clustervar = 'cve_num', -->
<!-- #         dataset = nussio_ne, -->
<!-- #         target = 'all', -->
<!-- #         drop_na_grf = T) -->


<!-- compare_tbl(model_list = list( -->
<!--                  append(list(original = m1), m1_grf_dml), -->
<!--                  append(list(original = m2), m2_grf_dml),  -->
<!--                  append(list(original = m3), m3_grf_dml), -->
<!--                  append(list(original = m4), m4_grf_dml), -->
<!--             treatment = NULL, -->
<!--             tidy = F) %>% -->
<!--   write_rds(here('replication', 'nussio_ne_rep.RDS')) -->

<!-- # Final table -->
<!-- # huxtable::huxreg(compare_tbl(list(list(m1, grf_out1, dml_out1), -->
<!-- #                                   list(m2, grf_out2, dml_out2), -->
<!-- #                                   list(m3, grf_out3, dml_out3), -->
<!-- #                                   list(m4, grf_out4, dml_out4), -->
<!-- #                                   list(m5, grf_out5, dml_out5), -->
<!-- #                                   list(m6, grf_out6, dml_out6)), -->
<!-- #                              tidy = F), -->
<!-- #                  statistics = NA) %>% -->
<!-- #   huxtable::insert_row(c('Control variables', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes'),  -->
<!-- #                        after = nrow(.) - 1) %>% -->
<!-- #   huxtable::set_caption('Replication of Nussio (2024) Table 5: "Natural Experiment: Earthquake Exposure and Lynching"') %>% -->
<!-- #   write_rds(here('replication', 'nussio_ne_tab.RDS')) -->
<!-- #  -->
<!-- # read_rds(here('replication', 'nussio_ne_tab.RDS')) -->
<!-- ``` -->




<!-- These simulations suggest that double robust methods with flexible machine learning algorithms may show some gains in bias reduction compared to traditional methods such as linear OLS regression. However, do these methods make a difference in practice? In this section, I replicate results from recent *American Sociological Review* articles using two double robust methods. I chose three papers that meet the following criteria: the authors were trying to estimate a causal effect, they used OLS or logistic regression, and they  posted replication code and data.   -->

<!-- The first paper I replicate is "Commitment through Sacrifice: How Longer Ramadan Fasting Strengthens Religiosity and Political Islam," by @aksoy_2022_commitment. Using the natural variation in daylight from year to year during Ramadan, the authors test the relationship between Ramadan fasting time and the vote share of Islamist political parties in Turkey. The second paper is "They Cant All Be Stars: The Matthew Effect, Cumulative Status Bias, and Status Persistence in NBA All-Star Elections" [@biegert_2023_they]. The authors use detailed records on NBA players' performance to study the effect of the previous year's All-Star nomination on being re-nominated in the current year. Lastly, I replicate "The 'Dark Side' of Community Ties: Collective Action and Lynching in Mexico" [@nussio_2024_dark]. The author estimates the effect of community ties in Mexico on individual participation in lynching or lynching rates at aggregate levels. -->


<!-- ## Evaluation Strategy -->

<!-- I replicate these papers using two double robust methods with machine learning. First, I use AIPW in conjunction with generalized random forests (GRF) using the `grf` package [@tibshirani_2024_grf]. Second, I use a partially linear model for DML with a SuperLearner that, like above, harnesses ensemble learning with GLM, glmnet, and XGBoost, using the `DoubleML` package [@bach_2022_doubleml].^[In the Supplementary Material, I present the results of using these packages to estimate the full set of simulations shown above. Results are fairly similar to my own R code, though computation time is notably faster.] Note that AIPW with GRF allows for heterogeneous treatment effects, while this version of DML does not. I use packages rather than my own R code for two reasons. First, these packages calculate asymptotic standard errors without the need for bootstrapping, allowing straightforward comparison with the statistical significance of results in the original papers. Second, both packages allow clustering of standard errors, which all three papers employ.   -->

<!-- Two aspects of these replications deserve further explanation. First, it is common in social science to drop observations with missing data for some covariates, a technique called the "complete case method" or "listwise deletion." Two of these papers deal with missing data in this way -- by decreasing the sample size. Some machine learning methods, on the other hand, use missing data informatively [@mayer_2020_doubly]; the `grf` package allows covariates (but not the outcome or treatment assignment) to be missing, using missingness itself as a splitting criterion in growing trees. Hence for data with moderate levels of missingness, I allow `grf` to work with the entire dataset. For `DoubleML`, I use the same samples as in the original papers -- in these cases only observations with complete cases for a given regression model. An exception is Table 5 for @nussio_2024_dark, where the number of observations with missing control variables is far larger than the number without missing data; hence I drop incomplete cases for all analyses. I describe the exact procedures for handling missingness in the notes for each table of results in the Supplementary Material.   -->

<!-- The second aspect is fixed effects. Fixed effects are commonly used in linear models; beginning with a categorical variable with $k$ group labels, one hot encoding converts this to $k-1$ dichotomous variables, and these are entered into the regression linearly. These are meant to account for between-group differences [@firebaugh_2013_fixed]. In the papers replicated here, @aksoy_2022_commitment use these types of fixed effects in all models, @biegert_2023_they use no fixed effects, and @nussio_2024_dark uses fixed effects in some models (details are in the table notes in the Supplementary Material). In many machine learning methods, categorical variables cannot be easily incorporated [@johannemann_2021_sufficient]. Adding a large number of information-poor dichotomous variables to flexible tree methods like GRF and XGBoost does not have a fixed effects interpretation, since these methods can can interact any variable with any other and apply non-linear transformations. In cases where a researcher would want to use fixed effects for time and other variables with a natural ordering, these can be entered as a single continuous variable, whose effect the model will allow to vary nonlinearly. But categorical variables without a natural ordering -- such as individual or group fixed effects -- need special treatment. Recently, @clarke_2024_double have developed an extension to DML that incorporates group-level fixed effects. In the first set analyses, I do not adjust for individual or group fixed effects in the machine learning replications (even when the original paper's model does), but in the final part of this section of the Supplementary Material, I present two of Clarke and Polselli's approaches to incorporating fixed effects in DML. Results change very little from standard DML.   -->

<!-- ## Results -->

<!-- ```{r replications, fig.height = 8, fig.cap = 'Replications of ASR papers using double robust machine learning methods. Bars represent 95-percent asymptotic confidence intervals.'} -->
<!-- aksoy_list <- readRDS(here('replication', 'aksoy_rep.RDS'))  -->
<!-- aksoy_list[[1]]$model <- '(1) Base' -->
<!-- aksoy_list[[2]]$model <- '(2) Covariates' -->
<!-- aksoy_list[[3]]$model <- '(3) Lagged dependent variable' -->

<!-- biegert_list <- readRDS(here('replication', 'biegert_rep.RDS'))  -->
<!-- biegert_list[[1]]$model <- '(1) No controls' -->
<!-- biegert_list[[2]]$model <- '(2) Baseline confounders' -->
<!-- biegert_list[[3]]$model <- '(3) Prior situation + performance' -->
<!-- biegert_list[[4]]$model <- '(4) Current performance' -->
<!-- biegert_list[[5]]$model <- '(5) Current situation' -->

<!-- nussio_ind_list <- readRDS(here('replication', 'nussio_ind_rep.RDS'))  -->
<!-- nussio_ind_list[[1]]$model <- '(1) Base' -->
<!-- nussio_ind_list[[2]]$model <- '(2) Some controls' -->
<!-- nussio_ind_list[[3]]$model <- '(3) All controls' -->
<!-- nussio_ind_list[[4]]$model <- '(4) Geographical FE' -->

<!-- nussio_ag_list <- readRDS(here('replication', 'nussio_ag_rep.RDS'))  -->
<!-- nussio_ag_list[[1]]$model <- '(1) Base' -->
<!-- nussio_ag_list[[2]]$model <- '(2) Some controls' -->
<!-- nussio_ag_list[[3]]$model <- '(3) All controls' -->
<!-- nussio_ag_list[[4]]$model <- '(4) Geographical FE' -->

<!-- nussio_ne_list <- readRDS(here('replication', 'nussio_ne_rep.RDS'))  -->
<!-- nussio_ne_list[[1]]$model <- '(1) Within 250 km of earthquake' -->
<!-- nussio_ne_list[[2]]$model <- '(2) Within 250 km of earthquake, controls' -->
<!-- nussio_ne_list[[3]]$model <- '(3) Earthquake damage' -->
<!-- nussio_ne_list[[4]]$model <- '(4) Earthquake damage, controls' -->

<!-- bind_rows( -->
<!--   mutate(bind_rows(aksoy_list), paper = 'A. Aksoy et al. (2022)'), -->
<!--   mutate(bind_rows(biegert_list), paper = 'B. Biegert et al. (2022)'), -->
<!--   mutate(bind_rows(nussio_ind_list), paper = 'C. Nussio et al. (2024) Table 2: Individual'), -->
<!--   mutate(bind_rows(nussio_ag_list), paper = 'D. Nussio et al. (2024) Table 4: Aggregate'), -->
<!--   mutate(bind_rows(nussio_ne_list), paper = 'E. Nussio et al. (2024) Table 5: Natural Experiment') -->
<!--   ) %>% -->
<!--   filter(term %in% c('Original', 'AIPW (GRF)', 'DML (SuperLearner)')) %>% -->
<!--   mutate(term = factor(term, levels = unique({.$term})), -->
<!--          paper = factor(paper, levels = unique({paper})), -->
<!--          model = factor(model, levels = rev(unique({.$model})))) %>% -->
<!--   ggplot(aes(x = model, y = estimate, color = term, shape = term)) + -->
<!--   geom_hline(yintercept = 0, color = 'grey') + -->
<!--   geom_pointrange(position = position_dodge(-0.7), -->
<!--                   aes(ymin = estimate - 1.96*std.error, ymax = estimate + 1.96*std.error)) +  -->
<!--   coord_flip() + -->
<!--   facet_wrap(~paper, scales = 'free', ncol = 1) + -->
<!--   labs(x = '', y = '') + -->
<!--   theme(legend.position = 'bottom') -->
<!-- ``` -->

<!-- Results of the replications are shown in Figure \@ref(fig:replications), with tables of coefficients and explanatory notes in the Supplementary Material. For each paper, I replicate the main results. I do not replicate models testing mechanisms, interactions, mediators, or placebos.   -->

<!-- The first paper, "Commitment through Sacrifice: How Longer Ramadan Fasting Strengthens Religiosity and Political Islam" [@aksoy_2022_commitment], finds an OLS coefficient of about 7, implying a half-hour increase in fasting time is associated with a 3.5 percentage point increase in Islamist vote share. As shown in Figure \@ref(fig:replications) Panel A, coefficients using the double robust methods are noticeably smaller (though not significantly different from the original coefficients). In Model 2, which includes covariates, the main coefficient is nonsignificant at the 5-percent level. In both cases, the double robust estimates are more precise, with smaller standard errors than the OLS results.   -->

<!-- The second paper, "They Cant All Be Stars: The Matthew Effect, Cumulative Status Bias, and Status Persistence in NBA All-Star Elections" [@biegert_2023_they]. The authors use logistic regression to estimate the effect of the previous year's All-Star nomination on being re-nominated in the current year. Panel B of Figure \@ref(fig:replications) shows the average marginal effects from the authors' original regressions alongside the double robust replications. Models 1 and 2 do not control for previous performance and find that a previous year's nomination increases the likelihood of being nominated by 45 to 60 percentage points. Model 3 isolates the effect of the previous year's nomination from performance in the previous year; the original paper found a much smaller coefficient once these controls were incorporated, giving a marginal effect of about 5 percentage points, but the double robust methods estimate large effect sizes, at 30 and 59 percentage points for AIPW (GRF) and DML (SuperLearner), respectively. Models 4 and 5 control for other current factors, and double robust estimates are somewhat smaller than in Model 3 but still much larger than the original paper's estimates.   -->

<!-- The third and final paper for replication is "The 'Dark Side' of Community Ties: Collective Action and Lynching in Mexico" [@nussio_2024_dark]. I present his three main analyses as separate panels. In his first analyses, he looks at individual propensity to participate in a lynching, using the log number of names of people a respondent knows in his or her colonia (neighborhood) in Mexico City as the independent variable. In OLS models with and without controls, the author finds a coefficient of about 0.03 for the logged variable, implying that a one-percent increase in names known is associated with about 0.0003 percentage points greater likelihood of participating in a lynching. As shown in Panel C of Figure \@ref(fig:replications), For AIPW (GRF), coefficients and statistical significance are very similar to the original OLS coefficients. DML (SuperLearner), however, shows nonsignificant or negative effects.   -->

<!-- Panel D of Figure \@ref(fig:replications) replicates Nussio's [-@nussio_2024_dark] second analysis, which aggregates to the municipal level. Models estimate the effect of neighborly cooperation -- operationalized by the proportion of respondents who think that most neighbors help each other in problems related to electric lighting -- on the log municipal lynching rate. The original OLS estimate was fairly stable across models with controls, at about a one percentage point increase in neighborly cooperation associated with a two-percent increase in the lynching rate [$\exp(2/100) = 1.02$]. This estimate is fairly stable across estimators, though (as shown in the Supplementary Material) this is one case where incorporating fixed effects in the DML models reduces coefficient sizes.   -->

<!-- Finally, Panel E of Figure \@ref(fig:replications) replicates Nussio's [-@nussio_2024_dark] natural experiment, where he estimates the effect of the Puebla earthquake on September 19, 2017, on the number of lynching events in a municipality, using panel data from 2000 to 2020. The original OLS models found that municipalities within 250 km of the earthquake or that experienced earthquake damage experienced an increase of about 0.1 in the number of lynchings in years after 2017 (the mean yearly lynchings per municipality is 0.034). While models for AIPW (GRF) are fairly similar to the original OLS estimates, DML (SuperLearner) estimates are double the original estimates.  -->

<!-- These replications show that results from the original OLS or logistic regressions that these papers employed are fairly robust. In most cases, effect sign and statistical significance are consistent across the original and double robust estimators. Notably, effect sizes for @aksoy_2022_commitment in the double robust models are smaller than the OLS estimates, reaching nonsignificance in one case. DML (SuperLearner) estimates for Nussio's [-@nussio_2024_dark] individual analysis change sign and significance, while the AIPW (GRF) estimates are close to the OLS estimates. However, the simulation results presented in the previous section suggested that the DML (SuperLearner) estimator has higher RMSE than both OLS and AIPW (GRF) (Figure \@ref(fig:dorie-results-rmse)), so perhaps the original results are reliable.^[The Supplementary Material shows that the DoubleML package with the SuperLearner has higher bias and RMSE in the simulations than my own R code.] Overall, these replications highlight the importance of testing the robustness of estimates to different models; double robust, machine learning methods sometimes do produce substantively different results from traditional methods.   -->

<!-- ## Replications with Fixed Effects -->

<!-- The tables below present estimates from the *ASR* replications discussed above, but with the addition of two other models implementing methods proposed by @clarke_2024_double that incorporate individual or group fixed effects into DML. The authors' package, `XTDML`, builds on the `DoubleML` package. I use two of their procedures. First, correlated random effects (CRE) models explicitly model the correlation between the group-level components in both the treatment and outcome models. Second, the authors' "hybrid" model combines CRE with a within-group estimator that partials out group means from all variables, similar to the mechanics of fixed effects in OLS. I present results using fixed effects for each model, whether or not the original model uses fixed effects. The original models from @aksoy_2022_commitment use fixed effects throughout. @biegert_2023_they do not employ fixed effects in any of their original models. @nussio_2024_dark uses fixed effects in the fourth model in Tables 2 and 4 and in all models in Table 5. -->


<!-- ```{r rep-aksoy} -->
<!-- readRDS(here('replication', 'aksoy_rep.RDS')) %>% -->
<!--   huxtable::huxreg(statistics = NA, -->
<!--                    note = '{stars}. Covariates include GDP growth, population, turnout, number of parliamentary seats in province in Model 2 and 3; Models 3 also adjusts for the lagged value of the dependent variable (i.e., one election lagged Islamic votes); cluster robust standard errors are in parentheses. The AIPW (GRF) model does not drop incomplete observations.') %>% -->
<!--   huxtable::insert_row(c('Covariates', 'No', rep('Yes', 2)), after = nrow(.) - 1) %>% -->
<!--   huxtable::insert_row(c('Lagged dependent variable', 'No', 'No', 'Yes'), after = nrow(.) - 1) %>% -->
<!--   huxtable::insert_row(c('Election year fixed effects', 'Yes', 'Yes', 'Yes'), after = nrow(.) - 1) %>% -->
<!--   huxtable::insert_row(c('Province fixed effects', 'Yes', 'Yes', 'Yes'), after = nrow(.) - 1) %>% -->
<!--   huxtable::set_top_border((nrow(.)-4):(nrow(.)-1), value = 0) %>% -->
<!--   huxtable::set_top_border((nrow(.)-4), 2:4) %>% -->
<!--   huxtable::set_caption('Replication of Aksoy et al. (2022) Table 2, models for outcome of Islamic Votes: "Effect of Fasting Hours (Daylength) during Ramadan on Various Outcome Variables Based on Regression Models That Include Fixed Effects for Provinces and Election Years"') %>% -->
<!--   huxtable::set_width(.8) %>% -->
<!--   huxtable::set_all_padding(0) %>% -->
<!--   huxtable::set_latex_float('h!') -->

<!-- # read_rds(here('replication', 'aksoy_tab.RDS')) %>% -->
<!-- #   huxtable::as_flextable() %>% -->
<!-- #   flextable::hline(7:8, 1:4, border = officer::fp_border(width = 0)) %>% -->
<!-- #   flextable::hline(7, 2:4) %>% -->
<!-- #   flextable::hline(9) %>% -->
<!-- #   flextable::set_caption('Replication of Aksoy et al. (2022) Table 2, models for outcome of Islamic Votes: "Effect of Fasting Hours (Daylength) during Ramadan on Various Outcome Variables Based on Regression Models That Include Fixed Effects for Provinces and Election Years"') -->
<!-- ``` -->

<!-- \newpage -->

<!-- ```{r rep-biegert} -->
<!-- readRDS(here('replication', 'biegert_rep.RDS')) %>% -->
<!--   huxtable::huxreg(statistics = NA, -->
<!--                    note = '{stars}. With no control variables, Model 1 could not be estimated using DML with a SuperLearner. Model 2 adjusts for year (fixed effects in original model), height (cm), position, age at league entry, being Black, and NBA tenure. Model 3 adds controls for the previous year\'s average points per 36 minutes, average assists per 36 minutes, average rebounds per 36 minutes, minutes played, whether the team reached playoffs, the team\'s win percentage, and whether it was a big market team. Model 4 adds controls for current average points, average assists, and average rebounds per 36 minutes. Model 5 additionally controls for current minutes played, whether the team reaches the playoffs, the team win percentage, and whether it is a big market team. Player clustered standard errors are in parentheses. None of the original models includes player fixed effects. The AIPW (GRF) model does not drop incomplete observations.') %>% -->
<!--   huxtable::insert_row(c('Baseline confounders', 'No', rep('Yes', 4)), after = nrow(.) - 1) %>% -->
<!--   huxtable::insert_row(c('Prior situation + performance', rep('No', 2), rep('Yes', 3)), after = nrow(.) - 1) %>% -->
<!--   huxtable::insert_row(c('Current performance', rep('No', 3), rep('Yes', 2)), after = nrow(.) - 1) %>% -->
<!--   huxtable::insert_row(c('Current situation', rep('No', 4), rep('Yes', 1)), after = nrow(.) - 1) %>% -->
<!--   # huxtable::insert_row(c('Cumul. AS + cumul. mediators', rep('No', 5), 'Yes'), after = nrow(.) - 1) %>% -->
<!--   huxtable::set_top_border((nrow(.)-4):(nrow(.)-1), value = 0) %>% -->
<!--   huxtable::set_top_border((nrow(.)-4), 2:6) %>% -->
<!--   huxtable::set_caption('Replication of Biegert et al. (2023) Table 3: "Average Marginal Effects from Logistic Regression Models of All-Star Nomination"') %>% -->
<!--   huxtable::set_width(1) %>% -->
<!--   huxtable::set_all_padding(0) %>% -->
<!--   huxtable::set_latex_float('h!') -->


<!-- # read_rds(here('replication', 'biegert_tab.RDS')) %>% -->
<!-- #   huxtable::as_flextable() %>% -->
<!-- #   flextable::hline(7:11, 1:7, border = officer::fp_border(width = 0)) %>% -->
<!-- #   flextable::hline(7, 2:7) %>% -->
<!-- #   flextable::padding(padding = 0, part = "all") %>%  -->
<!-- #   flextable::autofit() %>% -->
<!-- #   flextable::hline(12) %>% -->
<!-- #   flextable::set_caption('Replication of Biegert et al. (2023) Table 3: "Average Marginal Effects from Logistic Regression Models of All-Star Nomination"') -->
<!-- ``` -->

<!-- \newpage -->

<!-- ```{r rep-nussio-ind} -->
<!-- readRDS(here('replication', 'nussio_ind_rep.RDS')) %>% -->
<!--   huxtable::huxreg(statistics = NA, -->
<!--                    note = "{stars}. Data come from a representative survey of residents of Mexico City conducted in February 2022. Models estimate the effect of the log number of names that respondents know in their colonia (neighborhood) on whether they had ever participate in a lynching. Model 1 controls for the extent to which people trust others living in their neighborhood. Model 2 adds controls for education, age, female, number of light bulbs, and unemployment. Model 3 additionally controls for employment, being Catholic or non-religious, whether someone has participated in a fight, whether parents live in the colonia, trust in government, garbage on the street, and residential street block. Colonia clustered standard errors are in parentheses. Model 4 adds colonia fixed effects. The AIPW (GRF) model does not drop incomplete observations.") %>% -->
<!--   huxtable::insert_row(c('Colonia FE', 'No', 'No', 'No', 'Yes'), after = nrow(.) - 1) %>% -->
<!--   huxtable::insert_row(c('Control variables', 'No', 'Some', 'All', 'All'), after = nrow(.) - 1) %>% -->
<!--   huxtable::set_top_border((nrow(.)-2):(nrow(.)-1), value = 0) %>% -->
<!--   huxtable::set_top_border((nrow(.)-2), 2:5) %>% -->
<!--   huxtable::set_caption('Replication of Nussio (2024) Table 2: "Individual-Level Analysis: Community Ties and Lynching Participation"') %>% -->
<!--   huxtable::set_width(.8) %>% -->
<!--   huxtable::set_all_padding(0) %>% -->
<!--   huxtable::set_latex_float('h!') -->



<!-- # read_rds(here('replication', 'nussio_ind_tab.RDS')) %>% -->
<!-- #   huxtable::as_flextable() %>% -->
<!-- #   flextable::hline(7:8, 1:5, border = officer::fp_border(width = 0)) %>% -->
<!-- #   flextable::hline(7, 2:5) %>% -->
<!-- #   flextable::hline(9) %>% -->
<!-- #   flextable::set_caption('Replication of Nussio (2024) Table 2: "Individual-Level Analysis: Community Ties and Lynching Participation"') -->
<!-- ``` -->

<!-- \newpage -->

<!-- ```{r rep-nussio-ag} -->
<!-- readRDS(here('replication', 'nussio_ag_rep.RDS')) %>% -->
<!--   huxtable::huxreg(statistics = NA, -->
<!--                    note = "{stars}. Models estimate the effect of neighborly cooperation -- operationalized by the proportion of respondents who think that most neighbors help each other in problems related to electric lighting -- on the log municipal lynching rate. Model 1 adds controls for the proportion of respondents in a municipality that trust their neighbors. Model controls for population, area in square kilometers, poverty rate, Gini coefficient, share indigenous people, non-religious population, homicide rate, and robbery rate. Model 3 adds controls for household victimization and trust in army. Model 4 adds estado (state) fixed effects. Municipality clustered standard errors are in paratheses. The AIPW (GRF) model does not drop incomplete observations.") %>% -->
<!--   huxtable::insert_row(c('Control variables', 'No', 'Some', 'All', 'All'), after = nrow(.) - 1) %>% -->
<!--   huxtable::insert_row(c('Estado FE', 'No', 'No', 'No', 'Yes'), after = nrow(.) - 1) %>% -->
<!--   huxtable::insert_row(c('Estado clustered SE', 'Yes', 'Yes', 'Yes', 'No'), after = nrow(.) - 1) %>% -->
<!--   huxtable::set_top_border((nrow(.)-3):(nrow(.)-1), value = 0) %>% -->
<!--   huxtable::set_top_border((nrow(.)-3), 2:5) %>% -->
<!--   huxtable::set_caption('Replication of Nussio (2024) Table 4: "Aggregate-Level Analysis: Community Ties and Lynching Rate"') %>% -->
<!--   huxtable::set_width(.8) %>% -->
<!--   huxtable::set_all_padding(0) %>% -->
<!--   huxtable::set_latex_float('h!') -->

<!-- # read_rds(here('replication', 'nussio_ag_tab.RDS')) %>% -->
<!-- #   huxtable::as_flextable() %>% -->
<!-- #   flextable::hline(7:9, 1:5, border = officer::fp_border(width = 0)) %>% -->
<!-- #   flextable::hline(7, 2:5) %>% -->
<!-- #   flextable::hline(10) %>% -->
<!-- #   flextable::set_caption('Replication of Nussio (2024) Table 4: "Aggregate-Level Analysis: Community Ties and Lynching Rate"') -->
<!-- ``` -->

<!-- \newpage -->

<!-- ```{r rep-nussio-ne} -->
<!-- readRDS(here('replication', 'nussio_ne_rep.RDS')) %>% -->
<!--   huxtable::huxreg(statistics = NA, -->
<!--                    note = "{stars}. Models estimate the effect of the Puebla earthquake on September 19, 2017, on the number of lynching events. Data is a panel of Mexican municipalities from 2000 to 2020. Specific independent variables include having an earthquake within 250 km (Models 1 and 2) or having earthquake damage (Models 3 and 4), each interacted with a post-2017 indicator variable. Municipality clustered standard errors are in parentheses. The original models include two-way fixed effects for year and municipality. Model 2 and 4 additionally control for homicides, robberies, kidnappings, and infant mortality. Machine learning models control for year. All models drop incomplete observations; Models 1, and 3 have 51,597 observations, while Models 2, and 4 have 17,225 observations. Due to complications with continuous treatment effects, I do not present the original Models 5 and 6, where the independent variable was distance from the earthquake.") %>% -->
<!--   huxtable::insert_row(c('Control variables', 'No', 'Yes', 'No', 'Yes'),  -->
<!--                        after = nrow(.) - 1) %>% -->
<!--   huxtable::set_top_border((nrow(.)-1):(nrow(.)-1), value = 0) %>% -->
<!--   huxtable::set_top_border((nrow(.)-1), 2:5) %>% -->
<!--   huxtable::set_caption('Replication of Nussio (2024) Table 5: "Natural Experiment: Earthquake Exposure and Lynching"') %>% -->
<!--   huxtable::set_width(.8) %>% -->
<!--   huxtable::set_all_padding(0) %>% -->
<!--   huxtable::set_latex_float('h!') -->



<!-- # Final table -->
<!-- # huxtable::huxreg(compare_tbl(list(list(m1, grf_out1, dml_out1), -->
<!-- #                                   list(m2, grf_out2, dml_out2), -->
<!-- #                                   list(m3, grf_out3, dml_out3), -->
<!-- #                                   list(m4, grf_out4, dml_out4), -->
<!-- #                                   list(m5, grf_out5, dml_out5), -->
<!-- #                                   list(m6, grf_out6, dml_out6)), -->
<!-- #                              tidy = F), -->
<!-- #                  statistics = NA) %>% -->
<!-- #   huxtable::insert_row(c('Control variables', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes'),  -->
<!-- #                        after = nrow(.) - 1) %>% -->
<!-- #   huxtable::set_caption('Replication of Nussio (2024) Table 5: "Natural Experiment: Earthquake Exposure and Lynching"') %>% -->

<!-- # read_rds(here('replication', 'nussio_ne_tab.RDS')) %>% -->
<!-- #   huxtable::as_flextable() %>% -->
<!-- #   flextable::hline(7, 1:7, border = officer::fp_border(width = 0)) %>% -->
<!-- #   flextable::hline(7, 2:7) %>% -->
<!-- #   flextable::hline(8) %>% -->
<!-- #   flextable::padding(padding = 0, part = "all") %>%  -->
<!-- #   flextable::autofit() %>% -->
<!-- #   flextable::set_caption('Replication of Nussio (2024) Table 5: "Natural Experiment: Earthquake Exposure and Lynching"') -->
<!-- ``` -->


<!-- \newpage -->


<!-- # References -->

<!-- <div id="refs"></div> -->